\subsection{Exercices}

% --- Lois Binomiale et Bernoulli ---

\begin{exercicebox}[Exercice 1 : Loi Binomiale (Quiz)]
Un étudiant répond au hasard à un QCM de 10 questions. Chaque question a 4 choix de réponse, dont un seul est correct. Soit $X$ le nombre de bonnes réponses.
\begin{enumerate}
    \item Quelle loi suit $X$ ? Précisez ses paramètres.
    \item Quelle est la probabilité que l'étudiant ait exactement 5 bonnes réponses ?
    \item Quelle est la probabilité que l'étudiant ait au moins une bonne réponse ?
\end{enumerate}
\end{exercicebox}

\begin{exercicebox}[Exercice 2 : Loi Binomiale (Contrôle Qualité)]
Une usine produit des ampoules. 5\% des ampoules sont défectueuses. On prélève un lot de 20 ampoules. Soit $X$ le nombre d'ampoules défectueuses dans le lot.
\begin{enumerate}
    \item Quelle loi suit $X$ ? (On suppose le prélèvement "avec remise" ou d'une production très grande).
    \item Quelle est la probabilité qu'il n'y ait aucune ampoule défectueuse ?
    \item Quelle est la probabilité qu'il y ait exactement deux ampoules défectueuses ?
\end{enumerate}
\end{exercicebox}

\begin{exercicebox}[Exercice 3 : Espérance et Variance (Binomiale)]
Un archer touche la cible avec une probabilité $p=0.8$ à chaque tir. Il tire $n=40$ flèches. Soit $X$ le nombre de tirs réussis.
\begin{enumerate}
    \item Calculer l'espérance $E(X)$.
    \item Calculer la variance $\text{Var}(X)$ et l'écart-type $\text{SD}(X)$.
\end{enumerate}
\end{exercicebox}

\begin{exercicebox}[Exercice 4 : Loi de Bernoulli (Indicatrice)]
Soit $A$ un événement avec $P(A) = p$. Soit $I_A$ la variable indicatrice de $A$.
\begin{enumerate}
    \item Écrire la PMF de $I_A$.
    \item Calculer $E(I_A)$.
    \item Calculer $\text{Var}(I_A)$ en utilisant $\text{Var}(X) = E(X^2) - [E(X)]^2$. (Indice : $I_A^2 = I_A$).
\end{enumerate}
\end{exercicebox}

% --- Loi de Poisson ---

\begin{exercicebox}[Exercice 5 : Loi de Poisson (Emails)]
Un serveur de messagerie reçoit en moyenne 2 emails "spam" par minute. Soit $X$ le nombre de spams reçus en une minute.
\begin{enumerate}
    \item Quelle loi suit $X$ ?
    \item Quelle est la probabilité de recevoir exactement 3 spams en une minute ?
    \item Quelle est la probabilité de recevoir au plus 2 spams en une minute ?
\end{enumerate}
\end{exercicebox}

\begin{exercicebox}[Exercice 6 : Loi de Poisson (Échelle de temps)]
Une substance radioactive émet en moyenne $\lambda=4$ particules par seconde. Soit $Y$ le nombre de particules émises en 3 secondes.
\begin{enumerate}
    \item Quelle est la loi de $Y$ ? (Indice : ajuster le paramètre $\lambda$).
    \item Quelle est la probabilité que $Y=10$ ?
\end{enumerate}
\end{exercicebox}

\begin{exercicebox}[Exercice 7 : Approximation de Poisson (Binomiale)]
Un livre de 500 pages contient 1000 fautes de frappe distribuées au hasard. Soit $X$ le nombre de fautes de frappe sur une page donnée.
\begin{enumerate}
    \item Quelle est la loi exacte de $X$ ? (On suppose qu'une faute ne peut pas être à cheval sur deux pages).
    \item Par quelle loi peut-on approximer $X$ ? Précisez le paramètre.
    \item En utilisant l'approximation, calculez la probabilité qu'une page choisie au hasard contienne au moins une faute.
\end{enumerate}
\end{exercicebox}

% --- Lois Géométrique et Hypergéométrique ---

\begin{exercicebox}[Exercice 8 : Loi Géométrique (Échecs avant succès)]
On lance un dé équilibré jusqu'à obtenir un 6. Soit $X$ le nombre d'échecs (lancers qui ne sont pas 6) avant d'obtenir le premier 6.
\begin{enumerate}
    \item Quelle loi suit $X$ ? Précisez le paramètre $p$.
    \item Quelle est la probabilité d'échouer exactement 3 fois ? (c-à-d, le 6 arrive au 4ème lancer).
    \item Quelle est l'espérance du nombre d'échecs $E(X)$ ?
\end{enumerate}
\end{exercicebox}

\begin{exercicebox}[Exercice 9 : Loi Géométrique (Propriété)]
Soit $X \sim \text{Geom}(p)$ (comptant les échecs).
Quelle est la probabilité $P(X \ge k)$ ? C'est-à-dire, la probabilité d'avoir au moins $k$ échecs.
\end{exercicebox}

\begin{exercicebox}[Exercice 10 : Loi Hypergéométrique (Comité)]
Un club est composé de 12 hommes et 8 femmes. On choisit un comité de 5 personnes au hasard. Soit $X$ le nombre de femmes dans le comité.
\begin{enumerate}
    \item Quelle loi suit $X$ ? Précisez les paramètres.
    \item Quelle est la probabilité que le comité soit composé d'exactement 2 femmes ?
\end{enumerate}
\end{exercicebox}

\begin{exercicebox}[Exercice 11 : Loi Hypergéométrique (Pêche)]
Un lac contient 100 poissons, dont 10 ont été marqués. Un pêcheur attrape 8 poissons (sans remise). Soit $X$ le nombre de poissons marqués parmi les 8 attrapés.
\begin{enumerate}
    \item Quelle est la loi de $X$ ?
    \item Quelle est la probabilité qu'il n'attrape aucun poisson marqué ?
\end{enumerate}
\end{exercicebox}

\begin{exercicebox}[Exercice 12 : Binomiale vs Hypergéométrique]
Expliquez la différence fondamentale entre la loi Binomiale et la loi Hypergéométrique. Dans quel cas la loi Binomiale est-elle une bonne approximation de la loi Hypergéométrique ?
\end{exercicebox}

% --- PMF, CDF, Espérance Générale, LOTUS, Variance ---

\begin{exercicebox}[Exercice 13 : PMF (Trouver la constante)]
Soit $X$ une variable aléatoire discrète dont la PMF est donnée par $P(X=k) = c \cdot k^2$ pour $k \in \{1, 2, 3\}$. Pour toutes les autres valeurs, $P(X=x)=0$.
\begin{enumerate}
    \item Trouvez la valeur de la constante $c$.
    \item Calculez $P(X \ge 2)$.
\end{enumerate}
\end{exercicebox}

\begin{exercicebox}[Exercice 14 : Espérance (Jeu de Hasard)]
Un joueur paie 5€ pour jouer à un jeu. Il lance deux dés. Il gagne $S$ euros, où $S$ est la somme des deux dés. Soit $G$ son gain net (gain - mise).
\begin{enumerate}
    \item Rappeler $E(S)$ (espérance de la somme de two dés).
    \item Calculer $E(G)$. Le jeu est-il équitable ?
\end{enumerate}
\end{exercicebox}

\begin{exercicebox}[Exercice 15 : LOTUS (Jeu de Hasard 2)]
On lance un dé équilibré. Soit $X$ le résultat. Vous gagnez $g(X) = (X-3)^2$ euros.
\begin{enumerate}
    \item Calculez l'espérance de votre gain, $E[g(X)]$.
\end{enumerate}
\end{exercicebox}

\begin{exercicebox}[Exercice 16 : CDF (Fonction de Répartition)]
Soit $X$ une variable aléatoire avec la PMF suivante :
$P(X=0) = 0.2$, $P(X=1) = 0.5$, $P(X=2) = 0.3$.
\begin{enumerate}
    \item Écrivez la fonction de répartition $F_X(x) = P(X \le x)$.
    \item Calculez $P(0 < X \le 2)$.
    \item Calculez $P(X > 1)$.
\end{enumerate}
\end{exercicebox}

\begin{exercicebox}[Exercice 17 : Variance (Calcul)]
Pour la variable $X$ de l'exercice 16 :
\begin{enumerate}
    \item Calculez $E(X)$.
    \item Calculez $E(X^2)$ en utilisant LOTUS.
    \item Calculez $\text{Var}(X)$ en utilisant la formule $E(X^2) - [E(X)]^2$.
\end{enumerate}
\end{exercicebox}

\begin{exercicebox}[Exercice 18 : Propriétés de la Variance]
Soit $X$ une variable aléatoire avec $E(X)=10$ et $\text{Var}(X)=4$. Soit $Y = 5X - 2$.
\begin{enumerate}
    \item Calculez $E(Y)$.
    \item Calculez $\text{Var}(Y)$.
\end{enumerate}
\end{exercicebox}

% --- Linéarité et Indicateurs ---

\begin{exercicebox}[Exercice 19 : Linéarité de l'Espérance (Mélange)]
On lance un dé (résultat $D$) et une pièce (résultat $P$, 1 pour Pile, 0 for Face).
Soit $X = D + 3P$.
Calculez $E(X)$ en utilisant la linéarité de l'espérance.
\end{exercicebox}

\begin{exercicebox}[Exercice 20 : Indicateurs (Problème des Chapeaux)]
$n$ personnes jettent leur chapeau au centre d'une pièce. Les chapeaux sont mélangés, et chaque personne en reprend un au hasard. Soit $X$ le nombre de personnes qui reprennent leur propre chapeau.
\begin{enumerate}
    \item Définir $X$ comme une somme de $n$ variables indicatrices $I_i$. Que représente $I_i$ ?
    \item Quelle est la probabilité $P(I_i=1)$ ? (C-à-d, la probabilité que la personne $i$ reprenne son chapeau).
    \item Calculez $E(X)$ en utilisant la linéarité.
\end{enumerate}
\end{exercicebox}

\begin{exercicebox}[Exercice 21 : Indicateurs (Collectionneurs)]
On achète $n=5$ boîtes de céréales. Chaque boîte contient une figurine au hasard parmi $k=4$ types de figurines (types A, B, C, D). Soit $X$ le nombre de types de figurines *distincts* que nous avons obtenus.
\begin{enumerate}
    \item Soit $I_A$ l'indicatrice que nous avons obtenu au moins une figurine de type A.
    \item Calculez $P(I_A=0)$. (Probabilité de n'avoir *aucune* figurine A dans les 5 boîtes).
    \item Calculez $E(I_A)$.
    \item Exprimez $X$ en fonction d'indicatrices $I_A, I_B, I_C, I_D$ et calculez $E(X)$.
\end{enumerate}
\end{exercicebox}

\begin{exercicebox}[Exercice 22 : Variance (Propriétés)]
Prouvez que $\text{Var}(aX + b) = a^2 \text{Var}(X)$ pour des constantes $a$ et $b$.
\end{exercicebox}

% --- Exercices de Synthèse ---

\begin{exercicebox}[Exercice 23 : Identifier la Loi]
Pour chaque scénario, identifiez la loi discrète la plus appropriée (Bernoulli, Binomiale, Hypergéométrique, Géométrique, Poisson).
\begin{enumerate}
    \item On compte le nombre de "Face" lors de 20 lancers de pièce.
    \item On compte le nombre d'accidents à une intersection un jour donné (sachant un taux moyen de 1.5/jour).
    \item On compte le nombre de Rois dans une main de 5 cartes tirées d'un jeu de 52 cartes.
    \item On compte le nombre de lancers de dé nécessaires avant d'obtenir le premier 3 (en comptant les échecs).
    \item On vérifie si un seul composant électronique est défectueux ou non.
\end{enumerate}
\end{exercicebox}

\begin{exercicebox}[Exercice 24 : Espérance (Loi Hypergéométrique)]
Soit $X \sim \text{HG}(w, b, m)$ (tirage de $m$ boules parmi $w$ blanches et $b$ noires).
En utilisant des variables indicatrices, montrez que $E(X) = m \left( \frac{w}{w+b} \right)$.
(Indice : Soit $I_j$ l'indicatrice que la $j$-ème boule tirée est blanche, pour $j=1 \dots m$. $X = \sum I_j$. Calculez $E(I_j)$.)
\end{exercicebox}

\begin{exercicebox}[Exercice 25 : Variance (Poisson)]
On admet que si $X \sim \text{Bin}(n, p)$, $\text{Var}(X) = np(1-p)$.
En utilisant l'approximation Poisson $X_n \sim \text{Bin}(n, \lambda/n)$, que devient la variance lorsque $n \to \infty$ ?
\end{exercicebox}



\subsection{Corrections des Exercices}

\begin{correctionbox}[Correction Exercice 1 : Loi Binomiale (Quiz)]
1. $X$ suit une loi Binomiale, car c'est la somme de $n=10$ succès indépendants (bonnes réponses), chacun avec une probabilité $p = 1/4 = 0.25$. $X \sim \text{Bin}(10, 0.25)$.
2. $P(X=5) = \binom{10}{5} (0.25)^5 (1-0.25)^{10-5} = 252 \times (0.25)^5 (0.75)^5 \approx 0.0584$.
3. $P(X \ge 1) = 1 - P(X=0)$.
$P(X=0) = \binom{10}{0} (0.25)^0 (0.75)^{10} = (0.75)^{10} \approx 0.0563$.
$P(X \ge 1) = 1 - 0.0563 = 0.9437$.
\end{correctionbox}

\begin{correctionbox}[Correction Exercice 2 : Loi Binomiale (Contrôle Qualité)]
1. $X \sim \text{Bin}(n=20, p=0.05)$.
2. $P(X=0) = \binom{20}{0} (0.05)^0 (0.95)^{20} = (0.95)^{20} \approx 0.3585$.
3. $P(X=2) = \binom{20}{2} (0.05)^2 (0.95)^{18} = 190 \times (0.0025) \times (0.95)^{18} \approx 0.1887$.
\end{correctionbox}

\begin{correctionbox}[Correction Exercice 3 : Espérance et Variance (Binomiale)]
1. $X \sim \text{Bin}(40, 0.8)$. L'espérance est $E(X) = np = 40 \times 0.8 = 32$. (On s'attend à 32 tirs réussis).
2. $\text{Var}(X) = np(1-p) = 40 \times 0.8 \times 0.2 = 6.4$.
$\text{SD}(X) = \sqrt{\text{Var}(X)} = \sqrt{6.4} \approx 2.53$.
\end{correctionbox}

\begin{correctionbox}[Correction Exercice 4 : Loi de Bernoulli (Indicatrice)]
1. $I_A$ suit la loi de Bernoulli $\text{Bern}(p)$.
$P(I_A=1) = p$ et $P(I_A=0) = 1-p$.
2. $E(I_A) = 1 \cdot P(I_A=1) + 0 \cdot P(I_A=0) = 1 \cdot p + 0 = p$.
3. On utilise LOTUS pour $E(I_A^2)$:
$E(I_A^2) = (1^2) \cdot P(I_A=1) + (0^2) \cdot P(I_A=0) = 1 \cdot p + 0 = p$.
(Note : $I_A^2 = I_A$ car $1^2=1$ et $0^2=0$, donc $E(I_A^2) = E(I_A) = p$).
$\text{Var}(I_A) = E(I_A^2) - [E(I_A)]^2 = p - p^2 = p(1-p)$.
\end{correctionbox}

\begin{correctionbox}[Correction Exercice 5 : Loi de Poisson (Emails)]
1. $X$ suit une loi de Poisson de paramètre $\lambda=2$. $X \sim \text{Poisson}(2)$.
2. $P(X=3) = \frac{e^{-2} 2^3}{3!} = \frac{e^{-2} \times 8}{6} \approx 0.1804$.
3. $P(X \le 2) = P(X=0) + P(X=1) + P(X=2)$
$P(X=0) = \frac{e^{-2} 2^0}{0!} = e^{-2}$
$P(X=1) = \frac{e^{-2} 2^1}{1!} = 2e^{-2}$
$P(X=2) = \frac{e^{-2} 2^2}{2!} = 2e^{-2}$
$P(X \le 2) = e^{-2}(1 + 2 + 2) = 5e^{-2} \approx 0.6767$.
\end{correctionbox}

\begin{correctionbox}[Correction Exercice 6 : Loi de Poisson (Échelle de temps)]
1. Le taux est $\lambda=4$ par seconde. Sur 3 secondes, le taux moyen est $\lambda' = 4 \times 3 = 12$.
$Y \sim \text{Poisson}(12)$.
2. $P(Y=10) = \frac{e^{-12} 12^{10}}{10!} \approx 0.1048$.
\end{correctionbox}

\begin{correctionbox}[Correction Exercice 7 : Approximation de Poisson (Binomiale)]
1. C'est un tirage sans remise (une faute ne peut pas être comptée deux fois). C'est $\text{Hypergéométrique}$. (Ou $\text{Binomiale}$ si on considère que chaque mot a une prob $p$ d'être une faute, mais $n$ (nb de mots) est inconnu).
On peut aussi voir cela comme $n=1000$ essais (fautes) de Bernoulli où le succès est "tomber sur la page X" (prob $p=1/500$). $X \sim \text{Bin}(1000, 1/500)$.
2. La loi Binomiale $\text{Bin}(n=1000, p=1/500)$ a $n$ grand et $p$ petit.
On approxime par Poisson avec $\lambda = np = 1000 \times (1/500) = 2$.
$X \approx \text{Poisson}(2)$.
3. $P(X \ge 1) = 1 - P(X=0) = 1 - \frac{e^{-2} 2^0}{0!} = 1 - e^{-2} \approx 1 - 0.1353 = 0.8647$.
\end{correctionbox}

\begin{correctionbox}[Correction Exercice 8 : Loi Géométrique (Échecs avant succès)]
1. $X$ compte le nombre d'échecs avant le premier succès. Le succès est "obtenir 6", $p=1/6$.
$X \sim \text{Geom}(p=1/6)$.
2. On cherche $P(X=3)$. $P(X=k) = (1-p)^k p$.
$P(X=3) = (5/6)^3 \times (1/6) = \frac{125}{216} \times \frac{1}{6} = \frac{125}{1296} \approx 0.0965$.
3. $E(X) = \frac{q}{p} = \frac{1-p}{p} = \frac{5/6}{1/6} = 5$. (On s'attend à 5 échecs en moyenne).
\end{correctionbox}

\begin{correctionbox}[Correction Exercice 9 : Loi Géométrique (Propriété)]
$P(X \ge k)$ est la probabilité d'avoir au moins $k$ échecs.
Cela signifie que les $k$ premiers essais ont *tous* été des échecs.
La probabilité d'un échec est $q=1-p$. La probabilité de $k$ échecs consécutifs est $q^k$.
(Après ces $k$ échecs, peu importe ce qui se passe, la condition $X \ge k$ est remplie).
Donc, $P(X \ge k) = (1-p)^k$.
\end{correctionbox}

\begin{correctionbox}[Correction Exercice 10 : Loi Hypergéométrique (Comité)]
1. Tirage sans remise. Population totale $w+b = 20$. On s'intéresse aux femmes (disons "blanches", $w=8$). Les hommes sont "noires" ($b=12$). On tire $m=5$ personnes.
$X \sim \text{HG}(w=8, b=12, m=5)$.
2. $P(X=2) = \frac{\binom{w}{k} \binom{b}{m-k}}{\binom{w+b}{m}} = \frac{\binom{8}{2} \binom{12}{3}}{\binom{20}{5}} = \frac{28 \times 220}{15504} = \frac{6160}{15504} \approx 0.3973$.
\end{correctionbox}

\begin{correctionbox}[Correction Exercice 11 : Loi Hypergéométrique (Pêche)]
1. $w=10$ (marqués), $b=90$ (non marqués). $w+b=100$. $m=8$ (tirage).
$X \sim \text{HG}(w=10, b=90, m=8)$.
2. $P(X=0) = \frac{\binom{10}{0} \binom{90}{8}}{\binom{100}{8}} = \frac{1 \times \frac{90!}{8!82!}}{\frac{100!}{8!92!}} = \frac{90! 92!}{82! 100!} = \frac{90 \cdot \dots \cdot 83}{100 \cdot \dots \cdot 93} \approx 0.4166$.
\end{correctionbox}

\begin{correctionbox}[Correction Exercice 12 : Binomiale vs Hypergéométrique]
La différence est l'indépendance des tirages.
\begin{itemize}
    \item \textbf{Binomiale :} Modélise $n$ tirages \textit{avec remise} (ou indépendants). La probabilité de succès $p$ est constante.
    \item \textbf{Hypergéométrique :} Modélise $m$ tirages \textit{sans remise} d'une population finie. La probabilité de succès change à chaque tirage.
\end{itemize}
La Binomiale approxime bien l'Hypergéométrique lorsque la taille de la population ($w+b$) est très grande par rapport à la taille de l'échantillon ($m$). Dans ce cas, $p \approx w/(w+b)$ est presque constant.
\end{correctionbox}

\begin{correctionbox}[Correction Exercice 13 : PMF (Trouver la constante)]
1. La somme des probabilités doit valoir 1 : $\sum P(X=k) = 1$.
$P(X=1) + P(X=2) + P(X=3) = 1$
$c \cdot 1^2 + c \cdot 2^2 + c \cdot 3^2 = 1$
$c(1 + 4 + 9) = 1 \implies 14c = 1 \implies c = 1/14$.
2. $P(X \ge 2) = P(X=2) + P(X=3) = c \cdot 2^2 + c \cdot 3^2 = 4c + 9c = 13c = 13/14$.
\end{correctionbox}

\begin{correctionbox}[Correction Exercice 14 : Espérance (Jeu de Hasard)]
1. $E(S) = E(D_1 + D_2) = E(D_1) + E(D_2) = 3.5 + 3.5 = 7$.
2. $G = S - 5$ (Gain = Somme - Mise).
Par linéarité : $E(G) = E(S - 5) = E(S) - E(5) = E(S) - 5$.
$E(G) = 7 - 5 = 2$.
L'espérance de gain net est de 2€. Le jeu est très en faveur du joueur (et non équitable).
\end{correctionbox}

\begin{correctionbox}[Correction Exercice 15 : LOTUS (Jeu de Hasard 2)]
On cherche $E[g(X)] = E[(X-3)^2]$. On utilise LOTUS : $E[g(X)] = \sum g(x) P(X=x)$.
$E[(X-3)^2] = \sum_{k=1}^6 (k-3)^2 P(X=k) = \sum_{k=1}^6 (k-3)^2 \cdot (1/6)$
$= \frac{1}{6} \left[ (1-3)^2 + (2-3)^2 + (3-3)^2 + (4-3)^2 + (5-3)^2 + (6-3)^2 \right]$
$= \frac{1}{6} \left[ (-2)^2 + (-1)^2 + 0^2 + 1^2 + 2^2 + 3^2 \right]$
$= \frac{1}{6} [ 4 + 1 + 0 + 1 + 4 + 9 ] = \frac{19}{6} \approx 3.167€$.
\end{correctionbox}

\begin{correctionbox}[Correction Exercice 16 : CDF (Fonction de Répartition)]
1. $F_X(x)$ accumule les probabilités :
$F_X(x) = \begin{cases} 
      0 & \text{si } x < 0 \\
      0.2 & \text{si } 0 \le x < 1 \\
      0.2 + 0.5 = 0.7 & \text{si } 1 \le x < 2 \\
      0.7 + 0.3 = 1.0 & \text{si } x \ge 2 
   \end{cases}$
2. $P(0 < X \le 2) = P(X=1) + P(X=2) = 0.5 + 0.3 = 0.8$.
(Alternativement : $F_X(2) - F_X(0) = 1.0 - 0.2 = 0.8$).
3. $P(X > 1) = P(X=2) = 0.3$.
(Alternativement : $1 - P(X \le 1) = 1 - F_X(1) = 1 - 0.7 = 0.3$).
\end{correctionbox}

\begin{correctionbox}[Correction Exercice 17 : Variance (Calcul)]
1. $E(X) = \sum x P(X=x) = (0)(0.2) + (1)(0.5) + (2)(0.3) = 0 + 0.5 + 0.6 = 1.1$.
2. $E(X^2) = \sum x^2 P(X=x) = (0^2)(0.2) + (1^2)(0.5) + (2^2)(0.3) = 0 + 0.5 + (4)(0.3) = 0.5 + 1.2 = 1.7$.
3. $\text{Var}(X) = E(X^2) - [E(X)]^2 = 1.7 - (1.1)^2 = 1.7 - 1.21 = 0.49$.
\end{correctionbox}

\begin{correctionbox}[Correction Exercice 18 : Propriétés de la Variance]
1. $E(Y) = E(5X - 2) = E(5X) - E(2) = 5E(X) - 2 = 5(10) - 2 = 48$.
2. $\text{Var}(Y) = \text{Var}(5X - 2) = \text{Var}(5X) = 5^2 \text{Var}(X) = 25 \times 4 = 100$.
(La constante $b=-2$ n'affecte pas la dispersion).
\end{correctionbox}

\begin{correctionbox}[Correction Exercice 19 : Linéarité de l'Espérance (Mélange)]
On cherche $E(X) = E(D + 3P)$.
Par linéarité : $E(X) = E(D) + E(3P) = E(D) + 3E(P)$.
$E(D) = 3.5$ (espérance d'un dé).
$P$ est une Bernoulli $\text{Bern}(0.5)$. $E(P) = p = 0.5$.
$E(X) = 3.5 + 3(0.5) = 3.5 + 1.5 = 5.0$.
\end{correctionbox}

\begin{correctionbox}[Correction Exercice 20 : Indicateurs (Problème des Chapeaux)]
1. $I_i$ est la variable indicatrice de l'événement "la personne $i$ reprend son propre chapeau".
$X = \sum_{i=1}^n I_i$.
2. Il y a $n!$ permutations (arrangements) possibles des chapeaux. Il y a $(n-1)!$ permutations où la personne $i$ a son propre chapeau.
$P(I_i=1) = \frac{(n-1)!}{n!} = \frac{1}{n}$.
3. Par linéarité : $E(X) = E(\sum I_i) = \sum E(I_i)$.
$E(I_i) = P(I_i=1) = 1/n$.
$E(X) = \sum_{i=1}^n (1/n) = n \times (1/n) = 1$.
En moyenne, quel que soit $n$, une seule personne reprend son chapeau !
\end{correctionbox}

\begin{correctionbox}[Correction Exercice 21 : Indicateurs (Collectionneurs)]
1. $I_A = 1$ si on a au moins une fig. A, $I_A = 0$ sinon.
2. $P(I_A=0) = P(\text{n'avoir aucune fig. A})$. À chaque boîte, $P(\text{pas A}) = 3/4$.
Pour 5 boîtes indépendantes : $P(I_A=0) = (3/4)^5$.
3. $E(I_A) = P(I_A=1) = 1 - P(I_A=0) = 1 - (3/4)^5$.
4. $X$ est le nombre de types distincts, $X = I_A + I_B + I_C + I_D$.
Par linéarité : $E(X) = E(I_A) + E(I_B) + E(I_C) + E(I_D)$.
Par symétrie, $E(I_A) = E(I_B) = E(I_C) = E(I_D) = 1 - (3/4)^5$.
$E(X) = 4 \times \left( 1 - (3/4)^5 \right) \approx 4 \times (1 - 0.2373) = 4 \times 0.7627 = 3.0508$.
\end{correctionbox}

\begin{correctionbox}[Correction Exercice 22 : Variance (Propriétés)]
Soit $\mu = E(X)$. Alors $E(aX+b) = aE(X)+b = a\mu+b$.
Par définition de la variance :
$\text{Var}(aX+b) = E\left[ ( (aX+b) - E[aX+b] )^2 \right]$
$= E\left[ ( (aX+b) - (a\mu+b) )^2 \right]$
$= E\left[ ( aX - a\mu )^2 \right]$
$= E\left[ ( a(X - \mu) )^2 \right]$
$= E\left[ a^2 (X - \mu)^2 \right]$
$= a^2 E\left[ (X - \mu)^2 \right]$ (car $a^2$ est une constante)
$= a^2 \text{Var}(X)$.
\end{correctionbox}

\begin{correctionbox}[Correction Exercice 23 : Identifier la Loi]
1. \textbf{Binomiale} (n=20 essais de Bernoulli indépendants).
2. \textbf{Poisson} (comptage d'événements rares dans un intervalle fixe).
3. \textbf{Hypergéométrique} (tirage sans remise d'une population finie).
4. \textbf{Géométrique} (comptage d'échecs avant le premier succès).
5. \textbf{Bernoulli} (un seul essai, deux issues).
\end{correctionbox}

\begin{correctionbox}[Correction Exercice 24 : Espérance (Loi Hypergéométrique)]
Soit $I_j = 1$ si la $j$-ème boule tirée (pour $j=1 \dots m$) est blanche, $I_j=0$ sinon.
Le nombre total de blanches est $X = \sum_{j=1}^m I_j$.
Par linéarité, $E(X) = \sum_{j=1}^m E(I_j)$.
$E(I_j) = P(I_j=1)$. Quelle est la probabilité que la $j$-ème boule tirée soit blanche ?
Par symétrie (ou en considérant un tirage aléatoire), n'importe quelle boule a la même probabilité d'être à la $j$-ème position. Il y a $w$ blanches sur $w+b$ boules au total.
$P(I_j=1) = \frac{w}{w+b}$ (c'est vrai pour $j=1$, $j=2$, ... $j=m$).
$E(X) = \sum_{j=1}^m \frac{w}{w+b} = m \left( \frac{w}{w+b} \right)$.
\end{correctionbox}

\begin{correctionbox}[Correction Exercice 25 : Variance (Poisson)]
$X_n \sim \text{Bin}(n, \lambda/n)$.
$\text{Var}(X_n) = np(1-p) = n(\lambda/n)(1 - \lambda/n) = \lambda(1 - \lambda/n)$.
Lorsque $n \to \infty$ :
$\lim_{n \to \infty} \text{Var}(X_n) = \lim_{n \to \infty} \lambda(1 - \lambda/n)$
Puisque $\lambda/n \to 0$, la limite est $\lambda(1 - 0) = \lambda$.
On en déduit que pour $X \sim \text{Poisson}(\lambda)$, la variance est $\text{Var}(X) = \lambda$.
(L'espérance et la variance sont égales pour la loi de Poisson).
\end{correctionbox}

\subsection{Exercices Python}

Les exercices suivants appliquent les concepts de variables aléatoires continues (PDF, CDF, espérance, variance) en utilisant la bibliothèque \texttt{NumPy} pour la simulation numérique afin de vérifier les résultats théoriques.

\begin{codecell}
import numpy as np
import math
\end{codecell}

\begin{exercicebox}[Exercice 1 : PDF CDF et Espérance (Simulation)]
Soit $X$ une v.a. continue avec la PDF $f(x) = 2x$ pour $x \in [0, 1]$, et $f(x)=0$ sinon.
Par calcul (que vous pouvez faire à la main), on trouve :
\begin{itemize}
    \item CDF : $F(x) = x^2$ (pour $x \in [0, 1]$)
    \item Espérance : $E[X] = 2/3$
\end{itemize}
Nous pouvons simuler cette variable en utilisant la méthode de la transformée inverse : si $U \sim \text{Unif}(0, 1)$, alors $X = F^{-1}(U) = \sqrt{U}$ suit la loi de $X$.

\textbf{Votre tâche (avec NumPy) :}
\begin{enumerate}
    \item Générer $N=100000$ échantillons $U$ d'une loi Uniforme(0, 1) avec \texttt{np.random.rand}.
    \item Transformer ces échantillons pour obtenir $N$ échantillons de $X$ (en prenant la racine carrée).
    \item Calculer l'espérance empirique $E[X]$ (la moyenne de vos échantillons $X$) et la comparer à la valeur théorique $2/3$.
\end{enumerate}
\end{exercicebox}

\begin{exercicebox}[Exercice 2 : Variance (Simulation)]
En utilisant les échantillons $X$ de l'exercice 1.
La valeur théorique (calculée à la main) de la variance est $\text{Var}(X) = 1/18$.

\textbf{Votre tâche (avec NumPy) :}
\begin{enumerate}
    \item Calculer la variance empirique $\text{Var}(X)$ de vos échantillons $X$ avec \texttt{np.var}.
    \item Comparer le résultat empirique à la valeur théorique $1/18$.
\end{enumerate}
\end{exercicebox}

\begin{exercicebox}[Exercice 3 : Loi Uniforme (Simulation vs Théorie)]
Soit $X \sim \text{Unif}(a=5, b=15)$. Les valeurs théoriques sont $E[X] = \frac{a+b}{2}$ et $\text{Var}(X) = \frac{(b-a)^2}{12}$.

\textbf{Votre tâche (avec NumPy) :}
\begin{enumerate}
    \item Calculer l'espérance et la variance théoriques.
    \item Générer $N=100000$ échantillons aléatoires de $X$ avec \texttt{np.random.uniform}.
    \item Calculer l'espérance empirique (\texttt{np.mean}) et la variance empirique (\texttt{np.var}) des échantillons.
    \item Comparer les résultats empiriques aux résultats théoriques.
\end{enumerate}
\end{exercicebox}

\begin{exercicebox}[Exercice 4 : Loi Uniforme (Vérification de la PDF)]
Pour $X \sim \text{Unif}(5, 15)$, la PDF est $f(x) = \frac{1}{10}$ sur $[5, 15]$.
La probabilité $P(7 \le X \le 10)$ est $\int_7^{10} \frac{1}{10} dx = \frac{10-7}{10} = 0.3$.

\textbf{Votre tâche (avec NumPy) :}
\begin{enumerate}
    \item Utiliser les échantillons de $X$ de l'exercice 3.
    \item Calculer la probabilité empirique $P(7 \le X \le 10)$ en comptant la proportion d'échantillons qui tombent dans cet intervalle.
    \item Comparer le résultat empirique à la valeur théorique $0.3$.
\end{enumerate}
\end{exercicebox}

\begin{exercicebox}[Exercice 5 : Loi Exponentielle (Simulation vs Théorie)]
Soit $X \sim \text{Exp}(\lambda=0.5)$. Les valeurs théoriques sont $E[X] = \frac{1}{\lambda}$ et $\text{Var}(X) = \frac{1}{\lambda^2}$.

Note : \texttt{np.random.exponential} prend un paramètre "scale" $\beta = 1/\lambda$.

\textbf{Votre tâche (avec NumPy) :}
\begin{enumerate}
    \item Définir $\lambda$ et calculer $E[X]$ et $\text{Var}(X)$ théoriques.
    \item Calculer le paramètre $\beta$ (scale) pour NumPy.
    \item Générer $N=100000$ échantillons aléatoires de $X$.
    \item Calculer et comparer les espérances et variances empiriques et théoriques.
\end{enumerate}
\end{exercicebox}

\begin{exercicebox}[Exercice 6 : Loi Exponentielle (Vérification de la CDF)]
Pour $X \sim \text{Exp}(\lambda=0.5)$, la CDF est $F(x) = 1 - e^{-\lambda x}$.
Calculons $P(X \le 3) = F(3) = 1 - e^{-0.5 \times 3}$.

\textbf{Votre tâche (avec NumPy) :}
\begin{enumerate}
    \item Calculer la valeur théorique $F(3)$.
    \item Utiliser les échantillons de $X$ de l'exercice 5.
    \item Calculer la probabilité empirique $P(X \le 3)$ en comptant la proportion d'échantillons $\le 3$.
    \item Comparer les deux valeurs.
\end{enumerate}
\end{exercicebox}

\begin{exercicebox}[Exercice 7 : Propriété de Non-Mémoire (Exponentielle)]
Nous allons vérifier numériquement la propriété de non-mémoire $P(X > s+t \mid X > s) = P(X > t)$ en utilisant les échantillons de $X$ de l'exercice 5 ($\lambda=0.5$).

\textbf{Votre tâche (avec NumPy) :}
\begin{enumerate}
    \item Choisir $s=1$ et $t=2$.
    \item Calculer $P(X > t)$ (théoriquement $e^{-\lambda t}$). Calculer la probabilité empirique (proportion d'échantillons $> t$).
    \item Calculer $P(X > s+t \mid X > s)$ empiriquement :
        \begin{itemize}
            \item Filtrer les échantillons pour ne garder que ceux où $X > s$.
            \item Parmi ce sous-ensemble, calculer la proportion de ceux où $X > s+t$.
        \end{itemize}
    \item Comparer les deux probabilités empiriques.
\end{enumerate}
\end{exercicebox}

\begin{exercicebox}[Exercice 8 : Théorème de Transfert (LOTUS)]
Soit $X \sim \text{Unif}(0, 2)$. La PDF est $f(x)=1/2$.
Soit $g(X) = X^2$. Nous voulons $E[g(X)] = E[X^2]$.
Théoriquement : $E[X^2] = \int_0^2 x^2 f(x) \, dx = \int_0^2 x^2 (1/2) \, dx = \frac{1}{2} [\frac{x^3}{3}]_0^2 = \frac{1}{2} (\frac{8}{3}) = 4/3$.

\textbf{Votre tâche (avec NumPy) :}
\begin{enumerate}
    \item Générer $N=100000$ échantillons $X \sim \text{Unif}(0, 2)$.
    \item Créer les échantillons $Y = g(X) = X^2$.
    \item Calculer l'espérance empirique $E[Y]$ (la moyenne de $Y$).
    \item Comparer le résultat empirique à la valeur théorique $4/3$.
\end{enumerate}
\end{exercicebox}

\begin{exercicebox}[Exercice 9 : Linéarité de l'Espérance (E[aX+b])]
Soit $X \sim \text{Unif}(5, 15)$ (de l'exercice 3). Nous savons que $E[X] = 10$.
Soit $Y = 5X - 3$.
Par linéarité, l'espérance théorique est $E[Y] = E[5X - 3] = 5E[X] - 3$.

\textbf{Votre tâche (avec NumPy) :}
\begin{enumerate}
    \item Calculer $E[Y]$ théoriquement en utilisant $E[X] = 10$.
    \item Utiliser les échantillons $X$ de l'exercice 3.
    \item Créer les échantillons $Y = 5 \times X - 3$.
    \item Calculer l'espérance empirique $E[Y]$ (la moyenne de $Y$).
    \item Comparer les deux résultats.
\end{enumerate}
\end{exercicebox}

\begin{exercicebox}[Exercice 10 : Propriétés de la Variance (Var(aX+b))]
Soit $X \sim \text{Unif}(5, 15)$ (de l'exercice 3). $\text{Var}(X) = \frac{(15-5)^2}{12} = 100/12 \approx 8.333$.
Soit $Y = 5X - 3$.
Théoriquement : $\text{Var}(Y) = \text{Var}(5X - 3) = \text{Var}(5X) = 5^2 \text{Var}(X) = 25 \times \text{Var}(X)$.

\textbf{Votre tâche (avec NumPy) :}
\begin{enumerate}
    \item Calculer $\text{Var}(Y)$ théoriquement en utilisant $\text{Var}(X) = 100/12$.
    \item Utiliser les échantillons $Y$ de l'exercice 9.
    \item Calculer la variance empirique $\text{Var}(Y)$ (avec \texttt{np.var}).
    \item Comparer les deux résultats.
\end{enumerate}
\end{exercicebox}