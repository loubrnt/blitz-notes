\subsection{Exercices Python}

Ces exercices utilisent les \textbf{Lois des Grands Nombres (LLN)} pour estimer des paramètres de population à partir de simulations. La LLN garantit que la moyenne d'échantillon ($\bar{X}_n$) converge vers la vraie espérance ($\mu$) lorsque $n$ devient grand.

Nous utiliserons les données de \texttt{yfinance} pour établir des "vraies" valeurs ($\mu, \sigma^2$), puis nous simulerons des échantillons plus petits pour voir comment la moyenne de l'échantillon ($\bar{X}_n$) s'approche de $\mu$.

\begin{codecell}
!pip install yfinance
import yfinance as yf
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import norm

# Definir les tickers et la periode
tickers = ["GOOG"]
start_date = "2010-01-01"
end_date = "2024-12-31"

# Telecharger les prix de cloture ajustes
data = yf.download(tickers, start=start_date, end=end_date)["Adj Close"]

# Calculer les rendements journaliers en pourcentage
returns = data.pct_change().dropna()

# 'returns' est notre DataFrame principal.
# Considerons cette grande serie de donnees comme notre "Population"
# pour les besoins de ces exercices.
population_mean = returns.mean()
population_var = returns.var()
population_std = returns.std()

print(f"--- Population (GOOG 2010-2024) ---")
print(f"Vraie Moyenne (mu) = {population_mean:.6f}")
print(f"Vraie Variance (sigma^2) = {population_var:.6f}")
\end{codecell}

\begin{exercicebox}[Exercice 1 : Vérification de la Loi Faible (WLLN)]
La WLLN dit que $P(|\bar{X}_n - \mu| > \epsilon) \to 0$ lorsque $n \to \infty$. Nous allons vérifier que la variance de $\bar{X}_n$ diminue avec $n$, ce qui est la clé de la preuve de Chebyshev.

La théorie dit : $\text{Var}(\bar{X}_n) = \frac{\sigma^2}{n}$.

\textbf{Votre tâche :}
\begin{enumerate}
    \item Utiliser $\sigma^2$ (la variance de la population) calculée ci-dessus.
    \item Calculer la variance \textbf{théorique} de la moyenne d'échantillon $\text{Var}(\bar{X}_n)$ pour $n=10$, $n=100$, et $n=1000$.
    \item (Conclusion) Comment la variance de notre estimateur $\bar{X}_n$ évolue-t-elle lorsque $n$ augmente ? Qu'est-ce que cela implique sur la précision de notre estimation ?
\end{enumerate}
\end{exercicebox}

\begin{exercicebox}[Exercice 2 : Inégalité de Chebyshev]
Chebyshev donne une borne universelle : $P(|\bar{X}_n - \mu| \ge k) \le \frac{\text{Var}(\bar{X}_n)}{k^2}$.
Utilisons $n=100$ et $\epsilon = 0.01$ (soit un écart de 1\% du rendement journalier).

\textbf{Votre tâche :}
\begin{enumerate}
    \item Utiliser $\text{Var}(\bar{X}_{100})$ calculée à l'exercice 1.
    \item Fixer $k = \epsilon = 0.01$.
    \item Calculer la borne supérieure de probabilité (le côté droit de l'inégalité).
    \item (Conclusion) Interpréter cette borne : "Pour un échantillon de 100 jours, la probabilité que notre moyenne d'échantillon soit erronée de plus de 1\% est, au maximum, de...".
\end{enumerate}
\end{exercicebox}

\begin{exercicebox}[Exercice 3 : Simulation de la Loi Forte (SLLN) - Trajectoire]
La SLLN dit que $P(\lim_{n \to \infty} \bar{X}_n = \mu) = 1$. Nous allons simuler une "trajectoire" de $\bar{X}_n$ pour visualiser cette convergence.

\textbf{Votre tâche :}
\begin{enumerate}
    \item Prendre les 1000 premiers rendements de la série \texttt{returns}.
    \item Calculer la moyenne d'échantillon cumulative $\bar{X}_n$ pour $n=1, 2, 3, \dots, 1000$.
    \item (Indice : utiliser \texttt{.expanding().mean()} de pandas).
    \item \textbf{(Plot)} Tracer $\bar{X}_n$ en fonction de $n$ (de 1 à 1000).
    \item \textbf{(Plot)} Tracer une ligne horizontale constante à la "vraie" moyenne $\mu$ (la \texttt{population\_mean}).
    \item (Conclusion) La trajectoire de $\bar{X}_n$ converge-t-elle vers $\mu$ ?
\end{enumerate}
\end{exercicebox}

\begin{exercicebox}[Exercice 4 : Méthode de Monte-Carlo (Estimation de Probabilité)]
Nous voulons estimer $p = P(X > 0.02)$, la probabilité d'un "gros jour positif" (rendement > 2\%).
La vraie valeur $p$ est la proportion empirique sur toute la "population".
L'estimation $\bar{Z}_n$ est la proportion sur un échantillon de $n$ jours.

\textbf{Votre tâche :}
\begin{enumerate}
    \item Calculer la "vraie" probabilité $p$ (notre $\mu$) en comptant la proportion de \texttt{returns > 0.02} sur tout le dataset.
    \item Simuler 500 expériences. Dans \textbf{chaque} expérience :
        \begin{itemize}
            \item Tirer un échantillon de $n=50$ jours (avec remise) de \texttt{returns}.
            \item Estimer $\bar{Z}_{50}$ (la proportion de jours $> 0.02$ dans cet échantillon).
        \end{itemize}
    \item \textbf{(Plot)} Tracer l'histogramme de vos 500 estimations $\bar{Z}_{50}$.
    \item \textbf{(Plot)} Ajouter une ligne verticale à la "vraie" moyenne $p$.
    \item (Conclusion) Les estimations sont-elles centrées autour de la vraie valeur, comme prédit par la LLN ?
\end{enumerate}
\end{exercicebox}

\begin{exercicebox}[Exercice 5 : Estimation de $\pi$ (Monte-Carlo Pur)]
Appliquons l'exemple du cours pour estimer $\pi$ en utilisant la LLN.
Nous cherchons $\mu = \pi/4$. Nous estimons $\mu$ par $\bar{Z}_n = \frac{\text{Points dans le cercle}}{n}$.

\textbf{Votre tâche (avec NumPy) :}
\begin{enumerate}
    \item Définir $n = 1,000,000$.
    \item Générer $n$ coordonnées $X \sim U(0, 1)$ et $n$ coordonnées $Y \sim U(0, 1)$.
    \item Calculer $Z_i = 1$ si $X_i^2 + Y_i^2 \le 1$, et $0$ sinon. (Indice : \texttt{np.where} ou une comparaison booléenne).
    \item Calculer $\bar{Z}_n$ (la moyenne de $Z$).
    \item Calculer votre estimation de $\pi \approx 4 \cdot \bar{Z}_n$.
    \item (Conclusion) Votre estimation est-elle proche de \texttt{math.pi} ?
\end{enumerate}
\end{exercicebox}