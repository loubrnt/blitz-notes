\newpage
\section{Espérance et autres notions associées aux variables aléatoires discrètes }

\subsection{Espérance d'une variable aléatoire discrète}

\begin{definitionbox}[Espérance]
L'espérance (ou valeur attendue) d'une variable aléatoire discrète $X$, qui prend les valeurs distinctes $x_1, x_2, \dots$, est définie par :
$$ E(X) = \sum_j x_j P(X=x_j) $$
\end{definitionbox}

\begin{intuitionbox}
L'espérance représente la valeur moyenne que l'on obtiendrait si l'on répétait l'expérience un très grand nombre de fois. C'est le \textbf{centre de gravité} de la distribution de probabilité. Si les probabilités étaient des masses placées sur une tige aux positions $x_j$, l'espérance serait le point d'équilibre.
\end{intuitionbox}

\begin{examplebox}[Lancer d'un dé]
Soit $X$ le résultat d'un lancer de dé équilibré. Chaque face a une probabilité de $1/6$. L'espérance est :
$$ E(X) = 1\left(\frac{1}{6}\right) + 2\left(\frac{1}{6}\right) + 3\left(\frac{1}{6}\right) + 4\left(\frac{1}{6}\right) + 5\left(\frac{1}{6}\right) + 6\left(\frac{1}{6}\right) = \frac{21}{6} = 3.5 $$
Même si 3.5 n'est pas un résultat possible, c'est la valeur moyenne sur un grand nombre de lancers.
\end{examplebox}

\subsection{Linéarité de l'espérance}

\begin{theorembox}[Linéarité de l'espérance]
Pour toutes variables aléatoires $X$ et $Y$, et pour toute constante $c$, on a :
\begin{align*}
E(X+Y) &= E(X) + E(Y) \\
E(cX) &= cE(X)
\end{align*}
Cette propriété est extrêmement puissante car elle ne requiert pas que $X$ et $Y$ soient indépendantes.
\end{theorembox}

\begin{intuitionbox}
Cette propriété formalise une idée très simple : "la moyenne d'une somme est la somme des moyennes". Si vous jouez à deux jeux de hasard, votre gain moyen total est simplement la somme de ce que vous gagnez en moyenne à chaque jeu, que les jeux soient liés ou non.
\end{intuitionbox}

\begin{examplebox}[Somme de deux dés]
Soit $X_1$ le résultat du premier dé et $X_2$ celui du second. On sait que $E(X_1) = 3.5$ et $E(X_2) = 3.5$.
Soit $S = X_1 + X_2$ la somme des deux dés. Grâce à la linéarité, on peut calculer l'espérance de la somme sans avoir à lister les 36 résultats possibles :
$$ E(S) = E(X_1 + X_2) = E(X_1) + E(X_2) = 3.5 + 3.5 = 7 $$
\end{examplebox}

\subsection{Espérance de la loi binomiale}

\begin{theorembox}[Espérance de la loi binomiale]
Si $X \sim \text{Bin}(n, p)$, alors son espérance est $E(X) = np$.
\end{theorembox}

\begin{intuitionbox}
Ce résultat est très naturel. Si vous lancez une pièce 100 fois ($n=100$) avec une probabilité de 50\% d'obtenir Pile ($p=0.5$), vous vous attendez en moyenne à obtenir $100 \times 0.5 = 50$ Piles. La formule $np$ généralise cette idée.
\end{intuitionbox}

\begin{proofbox}
Le calcul direct de l'espérance avec la PMF binomiale est possible, mais long. En utilisant la linéarité de l'espérance, on obtient une preuve beaucoup plus courte et élégante.
\newline
On peut voir une variable binomiale $X$ comme la somme de $n$ variables de Bernoulli indépendantes, $X = I_1 + I_2 + \dots + I_n$, où chaque $I_j$ représente le succès (1) ou l'échec (0) du $j$-ième essai.
\newline
Chaque $I_j$ a pour espérance $E(I_j) = 1 \cdot p + 0 \cdot (1-p) = p$.
\newline
Par linéarité de l'espérance, on a :
$$ E(X) = E(I_1) + E(I_2) + \dots + E(I_n) = \underbrace{p + p + \dots + p}_{n \text{ fois}} = np $$
\end{proofbox}

\subsection{Espérance de la loi géométrique}
\begin{theorembox}[Espérance de la loi géométrique]
L'espérance d'une variable aléatoire $X \sim \text{Geom}(p)$ (comptant le nombre d'échecs) est :
$$ E(X) = \frac{1-p}{p} = \frac{q}{p} $$
\end{theorembox}

\begin{intuitionbox}
Si un événement a 1 chance sur 10 de se produire ($p=0.1$), il est logique de penser qu'il faudra en moyenne 9 échecs ($q/p = 0.9/0.1=9$) avant qu'il ne se produise. L'espérance du nombre total d'essais (échecs + 1 succès) serait alors $1/p$.
\end{intuitionbox}

\begin{proofbox}[Démonstration de l'espérance géométrique via les séries entières]
Soit $X \sim \text{Geom}(p)$, où $X$ compte le nombre d'échecs avant le premier succès. La PMF est $P(X=k) = q^k p$ pour $k=0, 1, 2, \dots$, avec $q=1-p$.
\newline
Par définition, l'espérance est :
$$ E(X) = \sum_{k=0}^{\infty} k \cdot P(X=k) = \sum_{k=0}^{\infty} k q^k p $$
Le terme pour $k=0$ est nul, on peut donc commencer la somme à $k=1$ :
$$ E(X) = p \sum_{k=1}^{\infty} k q^k $$
L'astuce consiste à reconnaître que la somme ressemble à la dérivée d'une série géométrique. Rappelons la formule de la série géométrique pour $|q|<1$ :
$$ \sum_{k=0}^{\infty} q^k = \frac{1}{1-q} $$
En dérivant les deux côtés par rapport à $q$, on obtient :
$$ \frac{d}{dq} \left( \sum_{k=0}^{\infty} q^k \right) = \frac{d}{dq} \left( \frac{1}{1-q} \right) $$
$$ \sum_{k=1}^{\infty} k q^{k-1} = \frac{1}{(1-q)^2} $$
Pour faire apparaître ce terme dans notre formule d'espérance, on factorise $q$ dans la somme :
$$ E(X) = p \cdot q \sum_{k=1}^{\infty} k q^{k-1} $$
On peut maintenant remplacer la somme par son expression analytique :
$$ E(X) = p \cdot q \cdot \frac{1}{(1-q)^2} $$
Puisque $p = 1-q$, on a :
$$ E(X) = p \cdot q \cdot \frac{1}{p^2} = \frac{q}{p} $$
Ce qui démontre que l'espérance du nombre d'échecs avant le premier succès est $\frac{q}{p}$.
\end{proofbox}

\subsection{Loi du statisticien inconscient (LOTUS)}

\begin{theorembox}[Théorème de Transfert (LOTUS)]
Si $X$ est une variable aléatoire discrète et $g(x)$ est une fonction de $\mathbb{R}$ dans $\mathbb{R}$, alors l'espérance de la variable aléatoire $g(X)$ est donnée par :
$$ E[g(X)] = \sum_x g(x) P(X=x) $$
La somme porte sur toutes les valeurs possibles de $X$. Ce théorème est utile car il évite d'avoir à trouver la PMF de $g(X)$.
\end{theorembox}

\begin{intuitionbox}
Pour trouver la valeur moyenne d'une fonction d'une variable aléatoire (par exemple, le carré du résultat d'un dé), vous n'avez pas besoin de déterminer d'abord la distribution de ce carré. Vous pouvez simplement prendre chaque valeur possible du résultat original, lui appliquer la fonction, et pondérer ce nouveau résultat par la probabilité du résultat original.
\end{intuitionbox}

\begin{examplebox}[Calcul de $E(X^2)$ pour un dé]
Soit $X$ le résultat d'un lancer de dé. Calculons l'espérance de $Y=X^2$. La fonction est $g(x)=x^2$.
\begin{align*}
E(X^2) &= \sum_{k=1}^6 k^2 P(X=k) \\
&= 1^2\left(\frac{1}{6}\right) + 2^2\left(\frac{1}{6}\right) + 3^2\left(\frac{1}{6}\right) + 4^2\left(\frac{1}{6}\right) + 5^2\left(\frac{1}{6}\right) + 6^2\left(\frac{1}{6}\right) \\
&= \frac{1+4+9+16+25+36}{6} = \frac{91}{6} \approx 15.17
\end{align*}
\end{examplebox}

\subsection{Variance}

\begin{definitionbox}[Variance et écart-type]
La \textbf{variance} d'une variable aléatoire $X$ mesure la dispersion de sa distribution autour de son espérance. Elle est définie par :
$$ \text{Var}(X) = E\left[ (X - E(X))^2 \right] $$
La racine carrée de la variance est appelée l' \textbf{écart-type} :
$$ \text{SD}(X) = \sqrt{\text{Var}(X)} $$
\end{definitionbox}

\begin{intuitionbox}
La variance est la "distance carrée moyenne à la moyenne". On prend l'écart de chaque valeur par rapport à la moyenne, on le met au carré (pour que les écarts positifs et négatifs ne s'annulent pas), puis on en calcule la moyenne. L'écart-type est souvent plus interprétable car il ramène cette mesure de dispersion dans les mêmes unités que la variable aléatoire elle-même.
\end{intuitionbox}

\begin{theorembox}[Formule de calcul de la variance]
Pour toute variable aléatoire $X$, une formule plus pratique pour le calcul de la variance est :
$$ \text{Var}(X) = E(X^2) - [E(X)]^2 $$
\end{theorembox}

\begin{examplebox}[Variance d'un lancer de dé]
Nous avons déjà calculé pour un dé que $E(X) = 3.5$ et $E(X^2) = 91/6$. On peut maintenant trouver la variance facilement :
$$ \text{Var}(X) = E(X^2) - [E(X)]^2 = \frac{91}{6} - (3.5)^2 = \frac{91}{6} - 12.25 = 15.166... - 12.25 \approx 2.917 $$
L'écart-type est $\text{SD}(X) = \sqrt{2.917} \approx 1.708$.
\end{examplebox}

\subsection{Exercices}

\begin{exercicebox}[Espérance d'un jeu]
Un jeu consiste à lancer un dé à six faces. Si vous obtenez un 6, vous gagnez 10€. Si vous obtenez un 4 ou un 5, vous gagnez 1€. Sinon, vous ne gagnez rien. Quelle est l'espérance de gain pour une partie ?
\end{exercicebox}

\begin{correctionbox}
Soit $X$ la variable aléatoire représentant le gain. Les valeurs possibles de $X$ sont 10, 1, et 0.
Les probabilités associées sont :
$P(X=10) = P(\text{obtenir un 6}) = 1/6$.
$P(X=1) = P(\text{obtenir un 4 ou 5}) = 2/6 = 1/3$.
$P(X=0) = P(\text{obtenir 1, 2 ou 3}) = 3/6 = 1/2$.

L'espérance de gain est :
$$ E(X) = 10 \cdot P(X=10) + 1 \cdot P(X=1) + 0 \cdot P(X=0) $$
$$ E(X) = 10 \cdot \frac{1}{6} + 1 \cdot \frac{2}{6} + 0 \cdot \frac{3}{6} = \frac{10+2}{6} = \frac{12}{6} = 2 $$
L'espérance de gain est de 2€ par partie.
\end{correctionbox}

\begin{exercicebox}[Linéarité de l'espérance]
On lance deux dés non truqués. Soit $X$ la somme des résultats. Calculez $E(X)$ en utilisant la linéarité de l'espérance.
\end{exercicebox}

\begin{correctionbox}
Soit $D_1$ le résultat du premier dé et $D_2$ le résultat du second dé. On a $X = D_1 + D_2$.
L'espérance du résultat d'un seul dé est $E(D_1) = E(D_2) = 3.5$.
Par linéarité de l'espérance :
$$ E(X) = E(D_1 + D_2) = E(D_1) + E(D_2) = 3.5 + 3.5 = 7 $$
L'espérance de la somme est 7.
\end{correctionbox}

\begin{exercicebox}[Espérance binomiale]
Un étudiant répond au hasard à un QCM de 20 questions, chaque question ayant 4 options de réponse (une seule correcte). Quelle est l'espérance du nombre de bonnes réponses ?
\end{exercicebox}

\begin{correctionbox}
Soit $X$ le nombre de bonnes réponses. Chaque question est une épreuve de Bernoulli avec une probabilité de succès $p=1/4$. Le nombre total d'épreuves est $n=20$.
$X$ suit donc une loi binomiale $X \sim \text{Bin}(n=20, p=0.25)$.
L'espérance d'une loi binomiale est $E(X) = np$.
$$ E(X) = 20 \times 0.25 = 5 $$
L'étudiant peut s'attendre à avoir 5 bonnes réponses en moyenne.
\end{correctionbox}

\begin{exercicebox}[Loi Géométrique]
On lance une pièce de monnaie jusqu'à obtenir "Pile" pour la première fois. La probabilité d'obtenir "Pile" est $p=0.5$.
\begin{enumerate}
    \item Quelle est la probabilité que le premier "Pile" apparaisse au 4ème lancer (c'est-à-dire après 3 "Face") ?
    \item Quel est le nombre moyen d'échecs ("Face") attendu avant le premier succès ?
\end{enumerate}
\end{exercicebox}

\begin{correctionbox}
Soit $X$ le nombre d'échecs avant le premier succès. $X \sim \text{Geom}(p=0.5)$.
1. On cherche $P(X=3)$. La PMF est $P(X=k) = (1-p)^k p$.
$$ P(X=3) = (0.5)^3 \times 0.5 = 0.125 \times 0.5 = 0.0625 $$
La probabilité est de 6.25\%.

2. On cherche l'espérance $E(X)$.
$$ E(X) = \frac{1-p}{p} = \frac{0.5}{0.5} = 1 $$
On s'attend en moyenne à 1 échec ("Face") avant le premier "Pile".
\end{correctionbox}

\begin{exercicebox}[Variance d'un dé]
Calculez la variance du résultat $X$ d'un lancer de dé équilibré.
\end{exercicebox}

\begin{correctionbox}
On utilise la formule $\text{Var}(X) = E(X^2) - [E(X)]^2$.
On sait déjà que $E(X)=3.5$.
Calculons $E(X^2)$ avec LOTUS :
$$ E(X^2) = \sum_{k=1}^6 k^2 P(X=k) = \frac{1}{6}(1^2+2^2+3^2+4^2+5^2+6^2) $$
$$ E(X^2) = \frac{1}{6}(1+4+9+16+25+36) = \frac{91}{6} \approx 15.167 $$
Maintenant, la variance :
$$ \text{Var}(X) = \frac{91}{6} - (3.5)^2 = \frac{91}{6} - 12.25 = \frac{91 - 73.5}{6} = \frac{17.5}{6} \approx 2.917 $$
\end{correctionbox}

\begin{exercicebox}[Loi de Poisson]
Un livre de 500 pages contient 250 fautes de frappe distribuées au hasard.
\begin{enumerate}
    \item Quel est le nombre moyen de fautes par page ?
    \item Quelle est la probabilité qu'une page choisie au hasard contienne exactement 2 fautes ?
\end{enumerate}
\end{exercicebox}

\begin{correctionbox}
1. Le taux moyen d'erreurs est $\lambda = \frac{250 \text{ fautes}}{500 \text{ pages}} = 0.5$ fautes par page.
Le nombre de fautes par page, $X$, suit une loi de Poisson $X \sim \text{Poisson}(\lambda=0.5)$.

2. On cherche $P(X=2)$. La PMF de Poisson est $P(X=k) = \frac{e^{-\lambda}\lambda^k}{k!}$.
$$ P(X=2) = \frac{e^{-0.5}(0.5)^2}{2!} = \frac{0.6065 \times 0.25}{2} \approx 0.0758 $$
La probabilité est d'environ 7.58\%.
\end{correctionbox}

\begin{exercicebox}[Variance et constante]
Soit $X$ une variable aléatoire avec $E(X)=10$ et $\text{Var}(X)=2$. Calculez l'espérance et la variance de $Y = 3X + 5$.
\end{exercicebox}

\begin{correctionbox}
On utilise les propriétés de l'espérance et de la variance.
Pour l'espérance :
$E(Y) = E(3X+5) = E(3X) + E(5) = 3E(X) + 5$.
$$ E(Y) = 3(10) + 5 = 35 $$
Pour la variance :
$\text{Var}(Y) = \text{Var}(3X+5) = \text{Var}(3X) = 3^2 \text{Var}(X)$.
$$ \text{Var}(Y) = 9 \times 2 = 18 $$
\end{correctionbox}

\begin{exercicebox}[Variable indicatrice]
On lance une pièce deux fois. Soit $A$ l'événement "obtenir au moins un Pile". Soit $I_A$ la variable indicatrice de cet événement. Donnez la PMF, l'espérance et la variance de $I_A$.
\end{exercicebox}

\begin{correctionbox}
L'univers est $\{PP, PF, FP, FF\}$. L'événement $A$ est $\{PP, PF, FP\}$.
La probabilité de A est $P(A) = 3/4$.
La variable $I_A$ vaut 1 si $A$ se produit, 0 sinon. C'est une loi de Bernoulli.
$I_A \sim \text{Bern}(p=3/4)$.

PMF : $P(I_A=1) = 3/4$ et $P(I_A=0) = 1/4$.
Espérance : $E(I_A) = p = 3/4$.
Variance : $\text{Var}(I_A) = p(1-p) = \frac{3}{4} \left(1-\frac{3}{4}\right) = \frac{3}{4} \cdot \frac{1}{4} = \frac{3}{16}$.
\end{correctionbox}

\begin{exercicebox}[Poisson comme approximation]
Une compagnie aérienne observe que 0.2\% des passagers qui réservent un vol ne se présentent pas. Si un avion a 200 sièges et que la compagnie vend 200 billets, quelle est la probabilité qu'exactement 3 passagers ne se présentent pas ? Utilisez l'approximation de Poisson.
\end{exercicebox}

\begin{correctionbox}
C'est une situation binomiale avec $n=200$ (grand) et $p=0.002$ (petit). On peut l'approximer par une loi de Poisson.
Le paramètre $\lambda$ est $\lambda = np = 200 \times 0.002 = 0.4$.
Soit $X$ le nombre de passagers absents, $X \sim \text{Poisson}(0.4)$. On cherche $P(X=3)$.
$$ P(X=3) = \frac{e^{-0.4}(0.4)^3}{3!} = \frac{0.6703 \times 0.064}{6} \approx 0.00715 $$
La probabilité est d'environ 0.715\%.
\end{correctionbox}

\begin{exercicebox}[LOTUS]
Une variable aléatoire discrète $X$ a la PMF suivante : $P(X=-1)=0.2$, $P(X=0)=0.5$, $P(X=1)=0.3$. Calculez $E[ (X+1)^2 ]$.
\end{exercicebox}

\begin{correctionbox}
On utilise le théorème de transfert (LOTUS) avec la fonction $g(x) = (x+1)^2$.
$$ E[g(X)] = \sum_x g(x) P(X=x) $$
$$ E[(X+1)^2] = (-1+1)^2 P(X=-1) + (0+1)^2 P(X=0) + (1+1)^2 P(X=1) $$
$$ E[(X+1)^2] = (0)^2 \cdot (0.2) + (1)^2 \cdot (0.5) + (2)^2 \cdot (0.3) $$
$$ E[(X+1)^2] = 0 + 1 \cdot 0.5 + 4 \cdot 0.3 = 0.5 + 1.2 = 1.7 $$
\end{correctionbox}

\begin{exercicebox}[Espérance d'une fonction]
Soit $X$ une variable aléatoire représentant le résultat d'un lancer d'un dé équilibré à 4 faces (valeurs 1, 2, 3, 4). Calculez l'espérance de $Y = 1/X$.
\end{exercicebox}

\begin{correctionbox}
Chaque face a une probabilité de $1/4$. On utilise le théorème de transfert (LOTUS) avec $g(x) = 1/x$.
$$ E(Y) = E(1/X) = \sum_{k=1}^4 \frac{1}{k} P(X=k) $$
$$ E(1/X) = \frac{1}{1}\left(\frac{1}{4}\right) + \frac{1}{2}\left(\frac{1}{4}\right) + \frac{1}{3}\left(\frac{1}{4}\right) + \frac{1}{4}\left(\frac{1}{4}\right) $$
$$ E(1/X) = \frac{1}{4} \left(1 + \frac{1}{2} + \frac{1}{3} + \frac{1}{4}\right) = \frac{1}{4} \left(\frac{12+6+4+3}{12}\right) = \frac{1}{4} \cdot \frac{25}{12} = \frac{25}{48} \approx 0.521 $$
\end{correctionbox}

\begin{exercicebox}[Loi Géométrique : "Sans mémoire"]
Un archer touche sa cible avec une probabilité $p=1/3$. Sachant qu'il a déjà manqué ses 5 premiers tirs, quelle est la probabilité qu'il touche la cible au 8ème tir (c'est-à-dire après 2 échecs supplémentaires) ?
\end{exercicebox}

\begin{correctionbox}
La loi géométrique est "sans mémoire". Le fait qu'il ait déjà manqué 5 tirs ne change pas les probabilités pour les tirs futurs. Le problème revient à se demander la probabilité qu'il lui faille 3 tirs supplémentaires pour réussir, ce qui équivaut à 2 échecs suivis d'un succès.
Soit $X$ le nombre d'échecs avant le premier succès. On cherche $P(X=2)$.
$$ P(X=2) = (1-p)^2 p = \left(\frac{2}{3}\right)^2 \left(\frac{1}{3}\right) = \frac{4}{9} \cdot \frac{1}{3} = \frac{4}{27} $$
\end{correctionbox}

\begin{exercicebox}[Loi de Poisson : Événements rares]
Dans une grande forêt, on observe en moyenne 0.8 ours par kilomètre carré. On étudie une zone de 5 km².
\begin{enumerate}
    \item Quel est le nombre moyen d'ours attendu dans cette zone ?
    \item Quelle est la probabilité de n'observer aucun ours dans cette zone ?
\end{enumerate}
\end{exercicebox}

\begin{correctionbox}
1. Le taux d'ours est de 0.8 par km². Pour une zone de 5 km², le paramètre $\lambda$ de la loi de Poisson est :
$$ \lambda = 0.8 \text{ ours/km²} \times 5 \text{ km²} = 4 $$
On s'attend donc à observer 4 ours en moyenne dans cette zone.

2. Soit $X$ le nombre d'ours observés, $X \sim \text{Poisson}(\lambda=4)$. On cherche $P(X=0)$.
$$ P(X=0) = \frac{e^{-4} 4^0}{0!} = e^{-4} \approx 0.0183 $$
La probabilité de n'observer aucun ours est d'environ 1.83\%.
\end{correctionbox}

\begin{exercicebox}[Variance d'une loi de Bernoulli]
Soit $X \sim \text{Bern}(p)$. Montrez en utilisant la formule $\text{Var}(X) = E(X^2) - [E(X)]^2$ que $\text{Var}(X) = p(1-p)$.
\end{exercicebox}

\begin{correctionbox}
Pour une variable de Bernoulli, $X$ ne peut prendre que les valeurs 0 et 1.
L'espérance est $E(X) = 1 \cdot p + 0 \cdot (1-p) = p$.
Pour calculer $E(X^2)$, on utilise LOTUS. Comme $X$ ne prend que les valeurs 0 et 1, $X^2$ est identique à $X$.
En effet, $0^2=0$ et $1^2=1$. Donc $X^2=X$.
Par conséquent, $E(X^2) = E(X) = p$.
On applique la formule de la variance :
$$ \text{Var}(X) = E(X^2) - [E(X)]^2 = p - p^2 = p(1-p) $$
\end{correctionbox}

\begin{exercicebox}[Loi Hypergéométrique]
Dans un groupe de 10 amis (6 hommes et 4 femmes), on tire au sort 3 personnes pour organiser une fête. Quelle est la probabilité que le groupe tiré au sort soit composé exclusivement de femmes ?
\end{exercicebox}

\begin{correctionbox}
Il s'agit d'un tirage sans remise. Soit $X$ le nombre de femmes tirées.
$X \sim \text{HG}(w=4 \text{ femmes}, b=6 \text{ hommes}, m=3 \text{ tirages})$.
On cherche $P(X=3)$.
$$ P(X=3) = \frac{\binom{\text{femmes}}{3} \binom{\text{hommes}}{0}}{\binom{\text{total}}{3}} = \frac{\binom{4}{3} \binom{6}{0}}{\binom{10}{3}} $$
$$ \binom{4}{3} = 4 \quad ; \quad \binom{6}{0} = 1 \quad ; \quad \binom{10}{3} = \frac{10 \cdot 9 \cdot 8}{3 \cdot 2 \cdot 1} = 120 $$
$$ P(X=3) = \frac{4 \times 1}{120} = \frac{4}{120} = \frac{1}{30} \approx 0.0333 $$
La probabilité est d'environ 3.33\%.
\end{correctionbox}

\begin{exercicebox}[Loi Binomiale : "Au moins"]
Un test de dépistage rapide a une probabilité de 0.1 de donner un faux positif. Si 10 personnes saines passent ce test, quelle est la probabilité qu'au moins deux d'entre elles reçoivent un faux positif ?
\end{exercicebox}

\begin{correctionbox}
Soit $X$ le nombre de faux positifs. $X \sim \text{Bin}(n=10, p=0.1)$.
On cherche $P(X \ge 2)$. Il est plus simple de calculer le complémentaire : $1 - P(X < 2)$.
$P(X < 2) = P(X=0) + P(X=1)$.
$$ P(X=0) = \binom{10}{0}(0.1)^0(0.9)^{10} = (0.9)^{10} \approx 0.3487 $$
$$ P(X=1) = \binom{10}{1}(0.1)^1(0.9)^9 = 10 \cdot 0.1 \cdot (0.9)^9 \approx 0.3874 $$
$P(X < 2) \approx 0.3487 + 0.3874 = 0.7361$.
$$ P(X \ge 2) = 1 - 0.7361 = 0.2639 $$
La probabilité d'avoir au moins deux faux positifs est d'environ 26.39\%.
\end{correctionbox}

\begin{exercicebox}[Écart-type]
Une machine distribue des boissons. La quantité versée $X$ (en cL) a pour espérance $E(X)=20$ et on a $E(X^2)=404$. Quel est l'écart-type de la quantité versée ?
\end{exercicebox}

\begin{correctionbox}
L'écart-type est la racine carrée de la variance. Calculons d'abord la variance.
$$ \text{Var}(X) = E(X^2) - [E(X)]^2 = 404 - (20)^2 = 404 - 400 = 4 $$
La variance est de 4 cL².
L'écart-type est :
$$ \text{SD}(X) = \sqrt{\text{Var}(X)} = \sqrt{4} = 2 $$
L'écart-type est de 2 cL.
\end{correctionbox}

\begin{exercicebox}[Espérance et prise de décision]
Vous avez le choix entre deux loteries.
Loterie A : Vous gagnez 100€ avec une probabilité de 0.1, sinon rien.
Loterie B : Vous gagnez 20€ avec une probabilité de 0.4, sinon rien.
Quelle loterie est la plus avantageuse en termes d'espérance de gain ?
\end{exercicebox}

\begin{correctionbox}
Calculons l'espérance de gain pour chaque loterie.
Soit $G_A$ le gain de la loterie A.
$$ E(G_A) = 100 \cdot P(G_A=100) + 0 \cdot P(G_A=0) = 100 \cdot 0.1 = 10€ $$
Soit $G_B$ le gain de la loterie B.
$$ E(G_B) = 20 \cdot P(G_B=20) + 0 \cdot P(G_B=0) = 20 \cdot 0.4 = 8€ $$
L'espérance de gain de la loterie A (10€) est supérieure à celle de la loterie B (8€). La loterie A est donc plus avantageuse en moyenne.
\end{correctionbox}

\begin{exercicebox}[Poisson : Somme de variables]
Deux sources radioactives émettent des particules indépendamment. La source 1 émet des particules selon une loi de Poisson de paramètre $\lambda_1=2$ par minute. La source 2 suit une loi de Poisson de paramètre $\lambda_2=3$ par minute. Quelle est la probabilité qu'un total de 4 particules soit émis en une minute ?
\end{exercicebox}

\begin{correctionbox}
Une propriété importante de la loi de Poisson est que la somme de deux variables de Poisson indépendantes est aussi une variable de Poisson dont le paramètre est la somme des paramètres.
Soit $X_1 \sim \text{Poisson}(2)$ et $X_2 \sim \text{Poisson}(3)$.
Le nombre total de particules $Y = X_1 + X_2$ suit une loi de Poisson de paramètre $\lambda = \lambda_1 + \lambda_2 = 2+3=5$.
Donc, $Y \sim \text{Poisson}(5)$.
On cherche $P(Y=4)$.
$$ P(Y=4) = \frac{e^{-5} 5^4}{4!} = \frac{e^{-5} \cdot 625}{24} \approx 0.1755 $$
La probabilité est d'environ 17.55\%.
\end{correctionbox}

\begin{exercicebox}[Contexte et choix du modèle]
Une petite ville compte 5000 habitants. En moyenne, 1 personne sur 1000 est allergique à une substance X.
\begin{enumerate}
    \item Quel modèle (Binomial ou Poisson) utiliseriez-vous pour estimer la probabilité qu'il y ait exactement 5 personnes allergiques dans cette ville ? Justifiez.
    \item Calculez cette probabilité.
\end{enumerate}
\end{exercicebox}

\begin{correctionbox}
1. Le modèle exact est une loi binomiale avec $n=5000$ et $p=1/1000=0.001$. Cependant, comme $n$ est très grand et $p$ est très petit, la loi de Poisson est une excellente approximation et bien plus simple à calculer. On utilisera donc une loi de Poisson.

2. Le paramètre de la loi de Poisson est $\lambda = np = 5000 \times 0.001 = 5$.
Soit $X$ le nombre de personnes allergiques, $X \sim \text{Poisson}(5)$.
On cherche $P(X=5)$.
$$ P(X=5) = \frac{e^{-5} 5^5}{5!} = \frac{e^{-5} \cdot 3125}{120} \approx 0.1755 $$
La probabilité est d'environ 17.55\%.
\end{correctionbox}