\subsection{Exercices}

\textit{Pour tous les exercices de calcul, vous pouvez utiliser les valeurs (arrondies) suivantes pour la fonction de répartition de la loi normale standard $\Phi(z) = P(Z \le z)$ :}
\begin{itemize}
    \item $\Phi(0) = 0.5$
    \item $\Phi(0.08) \approx 0.5319$
    \item $\Phi(0.1) \approx 0.5398$
    \item $\Phi(1.0) \approx 0.8413$
    \item $\Phi(1.5) \approx 0.9332$
    \item $\Phi(1.58) \approx 0.9429$
    \item $\Phi(1.645) \approx 0.95$
    \item $\Phi(1.75) \approx 0.9599$
    \item $\Phi(1.96) \approx 0.975$
    \item $\Phi(2.0) \approx 0.9772$
    \item $\Phi(2.33) \approx 0.99$
    \item $\Phi(2.5) \approx 0.9938$
    \item $\Phi(3.0) \approx 0.9987$
    \item $\Phi(10.0) \approx 1.0$
\end{itemize}
\textit{Et rappelez-vous la propriété de symétrie : $\Phi(-z) = 1 - \Phi(z)$.}

% --- Section 1 : Inégalité de Chebyshev ---

\begin{exercicebox}[Exercice 1 : Chebyshev (Calcul de base)]
Une variable aléatoire $Y$ a une moyenne $\mu=50$ et une variance $\sigma^2=16$.
Utilisez l'inégalité de Chebyshev pour trouver une borne supérieure à $P(|Y - 50| \ge 10)$.
\end{exercicebox}

\begin{exercicebox}[Exercice 2 : Chebyshev (En termes d'écarts-types)]
Quelle est la borne \textit{universelle} (valable pour toute distribution) pour la probabilité qu'une variable aléatoire s'écarte de sa moyenne de plus de 5 écarts-types ?
\end{exercicebox}

\begin{exercicebox}[Exercice 3 : Chebyshev (Application à $\bar{X}_n$)]
Soit $X_i$ une suite de v.a. i.i.d. avec $\mu=100$ et $\sigma^2=400$. Soit $n=100$.
\begin{enumerate}
    \item Calculez $E[\bar{X}_{100}]$ et $\text{Var}(\bar{X}_{100})$.
    \item En utilisant Chebyshev, bornez $P(|\bar{X}_{100} - 100| \ge 4)$.
\end{enumerate}
\end{exercicebox}

% --- Section 2 : CLT (Forme $\bar{X}_n$) ---

\begin{exercicebox}[Exercice 4 : CLT (Distribution de $\bar{X}_n$)]
On prélève un échantillon de $n=64$ observations d'une population de moyenne $\mu=20$ et de variance $\sigma^2=16$.
Quelle est la distribution approximative de la moyenne d'échantillon $\bar{X}_{64}$ selon le TCL ?
\end{exercicebox}

\begin{exercicebox}[Exercice 5 : CLT (Calcul de probabilité pour $\bar{X}_n$)]
En utilisant les informations de l'exercice 4, calculez $P(\bar{X}_{64} \le 21)$.
\end{exercicebox}

\begin{exercicebox}[Exercice 6 : CLT (Calcul de probabilité pour $\bar{X}_n$)]
On prélève $n=100$ observations d'une population de moyenne $\mu=50$ et d'écart-type $\sigma=5$.
Calculez $P(49 \le \bar{X}_{100} \le 51)$.
\end{exercicebox}

\begin{exercicebox}[Exercice 7 : CLT (Inverse pour $\bar{X}_n$)]
Soit $\bar{X}_n$ la moyenne de $n=36$ v.a. i.i.d. de moyenne $\mu=10$ et de variance $\sigma^2=81$.
Trouvez la valeur $c$ telle que $P(\bar{X}_{36} \le c) \approx 0.9772$.
\end{exercicebox}

% --- Section 3 : CLT (Forme $S_n$) ---

\begin{exercicebox}[Exercice 8 : CLT (Distribution de $S_n$)]
On prélève un échantillon de $n=100$ observations d'une population de moyenne $\mu=10$ et de variance $\sigma^2=4$.
Quelle est la distribution approximative de la somme $S_{100} = \sum X_i$ selon le TCL ?
\end{exercicebox}

\begin{exercicebox}[Exercice 9 : CLT (Calcul de probabilité pour $S_n$)]
En utilisant les informations de l'exercice 8, calculez $P(S_{100} > 1020)$.
\end{exercicebox}

\begin{exercicebox}[Exercice 10 : CLT (Application $S_n$)]
Un ascenseur doit transporter $n=49$ personnes. Le poids de chaque personne est une v.a. i.i.d. de moyenne $\mu=70$kg et d'écart-type $\sigma=14$kg.
Calculez la probabilité que le poids total $S_{49}$ dépasse 3500 kg.
\end{exercicebox}

\begin{exercicebox}[Exercice 11 : CLT (Inverse pour $S_n$)]
Soit $S_n$ la somme de $n=64$ v.a. i.i.d. de moyenne $\mu=5$ et de variance $\sigma^2=1$.
Trouvez la valeur $c$ telle que $P(S_{64} > c) \approx 0.05$.
\end{exercicebox}

% --- Section 4 : Approximation Normale de la Loi Binomiale ---

\begin{exercicebox}[Exercice 12 : Règle d'Approximation]
Peut-on approximer une loi $X \sim \text{Bin}(n=40, p=0.1)$ par une loi normale en utilisant la règle $np \ge 10$ et $n(1-p) \ge 10$ ?
\end{exercicebox}

\begin{exercicebox}[Exercice 13 : Règle d'Approximation]
Peut-on approximer une loi $X \sim \text{Bin}(n=500, p=0.04)$ par une loi normale en utilisant la règle $np \ge 10$ et $n(1-p) \ge 10$ ?
\end{exercicebox}

\begin{exercicebox}[Exercice 14 : Paramètres d'Approximation]
Soit $X \sim \text{Bin}(100, 0.3)$. On souhaite l'approximer par $Y \sim \mathcal{N}(\mu_Y, \sigma_Y^2)$.
Calculez $\mu_Y$ et $\sigma_Y^2$.
\end{exercicebox}

\begin{exercicebox}[Exercice 15 : Correction de Continuité (Règles)]
Soit $X$ une variable binomiale (discrète) et $Y$ son approximation normale (continue).
Traduisez les probabilités discrètes suivantes en probabilités continues :
\begin{enumerate}
    \item $P(X = 50)$
    \item $P(X \ge 50)$
    \item $P(X \le 49)$
    \item $P(X < 49)$
\end{enumerate}
\end{exercicebox}

\begin{exercicebox}[Exercice 16 : Correction de Continuité (Règles)]
Traduisez les probabilités discrètes suivantes en probabilités continues :
\begin{enumerate}
    \item $P(X > 30)$
    \item $P(30 < X < 40)$
    \item $P(30 \le X \le 40)$
\end{enumerate}
\end{exercicebox}

% --- Section 5 : Calculs Complets (Approximation Binomiale) ---

\begin{exercicebox}[Exercice 17 : Binomiale (Calcul P(X=k))]
On lance une pièce équilibrée 100 fois. Soit $X$ le nombre de "Pile".
Utilisez l'approximation normale (avec correction de continuité) pour estimer $P(X=50)$.
(C'est l'exemple du texte).
\end{exercicebox}

\begin{exercicebox}[Exercice 18 : Binomiale (Calcul $P(X \ge k)$)]
On lance une pièce équilibrée 100 fois ($X \sim \text{Bin}(100, 0.5)$).
Estimez $P(X \ge 60)$.
\end{exercicebox}

\begin{exercicebox}[Exercice 19 : Binomiale (Calcul $P(X \le k)$)]
Un traitement a un taux de succès de $p=0.2$. On l'administre à $n=400$ patients. Soit $X$ le nombre de succès.
Estimez $P(X \le 70)$.
\end{exercicebox}

\begin{exercicebox}[Exercice 20 : Binomiale (Calcul $P(X > k)$)]
En utilisant la situation de l'exercice 19 ($X \sim \text{Bin}(400, 0.2)$), estimez $P(X > 92)$.
\end{exercicebox}

\begin{exercicebox}[Exercice 21 : Binomiale (Calcul $P(k_1 \le X \le k_2)$)]
Un sondage est mené auprès de $n=100$ personnes. On suppose que $p=0.6$ est la probabilité qu'une personne soutienne une mesure. Soit $X$ le nombre de supporters.
Estimez $P(50 \le X \le 65)$.
\end{exercicebox}

% --- Section 6 : Synthèse ---

\begin{exercicebox}[Exercice 22 : TCL vs Chebyshev]
Soit $\bar{X}_{100}$ la moyenne de $n=100$ v.a. i.i.d. de moyenne $\mu=10$ et $\sigma^2=25$.
Calculez $P(|\bar{X}_{100} - 10| \ge 1)$ en utilisant :
\begin{enumerate}
    \item L'inégalité de Chebyshev.
    \item Le Théorème Central Limite.
\end{enumerate}
\end{exercicebox}

\begin{exercicebox}[Exercice 23 : Taille d'Échantillon (CLT)]
Soient $X_i$ des v.a. i.i.d. avec $\mu=0$ et $\sigma^2=1$.
Combien d'échantillons $n$ faut-il pour garantir que $P(|\bar{X}_n| \le 0.1) \ge 0.95$ ?
(Indice : $P(-1.96 \le Z \le 1.96) = 0.95$).
\end{exercicebox}

\begin{exercicebox}[Exercice 24 : LLN vs CLT]
Considérons $\bar{X}_n$ pour des $X_i$ i.i.d. avec $\mu=10, \sigma^2=100$.
\begin{enumerate}
    \item Calculez $P(9 \le \bar{X}_n \le 11)$ pour $n=100$.
    \item Calculez $P(9 \le \bar{X}_n \le 11)$ pour $n=10000$.
    \item Comment ce résultat illustre-t-il la LLN ?
\end{enumerate}
\end{exercicebox}

\begin{exercicebox}[Exercice 25 : Binomiale (Sans Correction)]
Soit $X \sim \text{Bin}(400, 0.1)$. Estimez $P(X \le 30.5)$ \textit{sans} utiliser la correction de continuité (c'est-à-dire en approximant $P(X \le 30.5) \approx P(Y \le 30.5)$).
(Ceci permet de comparer avec l'exercice 19).
\end{exercicebox}


\subsection{Corrections des Exercices}

\begin{correctionbox}[Correction Exercice 1 : Chebyshev (Calcul de base)]
$P(|Y - \mu| \ge k) \le \frac{\sigma^2}{k^2}$.
$P(|Y - 50| \ge 10) \le \frac{16}{10^2} = \frac{16}{100} = 0.16$.
La probabilité est d'au maximum 16\%.
\end{correctionbox}

\begin{correctionbox}[Correction Exercice 2 : Chebyshev (En termes d'écarts-types)]
On pose $k = 5\sigma$.
$P(|Y - \mu| \ge 5\sigma) \le \frac{\sigma^2}{(5\sigma)^2} = \frac{\sigma^2}{25\sigma^2} = \frac{1}{25} = 0.04$.
La probabilité est d'au maximum 4\%.
\end{correctionbox}

\begin{correctionbox}[Correction Exercice 3 : Chebyshev (Application à $\bar{X}_n$)]
1.  $E[\bar{X}_{100}] = \mu = 100$.
    $\text{Var}(\bar{X}_{100}) = \frac{\sigma^2}{n} = \frac{400}{100} = 4$.
2.  On applique Chebyshev à $\bar{X}_{100}$ (avec $\mu=100, \sigma^2=4$) et $k=4$.
    $P(|\bar{X}_{100} - 100| \ge 4) \le \frac{\text{Var}(\bar{X}_{100})}{k^2} = \frac{4}{4^2} = \frac{4}{16} = 0.25$.
\end{correctionbox}

\begin{correctionbox}[Correction Exercice 4 : CLT (Distribution de $\bar{X}_n$)]
$E[\bar{X}_{64}] = \mu = 20$.
$\text{Var}(\bar{X}_{64}) = \frac{\sigma^2}{n} = \frac{16}{64} = 0.25$.
Selon le TCL, $\bar{X}_{64} \approx \mathcal{N}(20, 0.25)$.
\end{correctionbox}

\begin{correctionbox}[Correction Exercice 5 : CLT (Calcul de probabilité pour $\bar{X}_n$)]
On standardise $\bar{X}_{64} \approx \mathcal{N}(20, 0.25)$, donc $\sigma_{\bar{X}} = \sqrt{0.25} = 0.5$.
On cherche $P(\bar{X}_{64} \le 21)$.
$Z = \frac{\bar{X}_n - \mu}{\sigma_{\bar{X}}} = \frac{21 - 20}{0.5} = \frac{1}{0.5} = 2$.
$P(\bar{X}_{64} \le 21) = P(Z \le 2) = \Phi(2) \approx 0.9772$.
\end{correctionbox}

\begin{correctionbox}[Correction Exercice 6 : CLT (Calcul de probabilité pour $\bar{X}_n$)]
$\mu=50, \sigma=5, n=100$. $\bar{X}_{100} \approx \mathcal{N}(\mu, \sigma^2/n)$.
$\mu_{\bar{X}} = 50$. $\sigma_{\bar{X}} = \sigma / \sqrt{n} = 5 / \sqrt{100} = 0.5$.
On cherche $P(49 \le \bar{X}_{100} \le 51)$.
$Z_1 = \frac{49 - 50}{0.5} = -2$. $Z_2 = \frac{51 - 50}{0.5} = 2$.
$P(-2 \le Z \le 2) = \Phi(2) - \Phi(-2) = \Phi(2) - (1 - \Phi(2)) = 2\Phi(2) - 1$.
$P \approx 2(0.9772) - 1 = 1.9544 - 1 = 0.9544$. (La règle des 95\%).
\end{correctionbox}

\begin{correctionbox}[Correction Exercice 7 : CLT (Inverse pour $\bar{X}_n$)]
$\mu=10, \sigma^2=81, n=36$. $\bar{X}_{36} \approx \mathcal{N}(\mu, \sigma^2/n)$.
$\mu_{\bar{X}} = 10$. $\sigma_{\bar{X}} = \sigma / \sqrt{n} = 9 / \sqrt{36} = 9 / 6 = 1.5$.
On cherche $c$ tel que $P(\bar{X}_{36} \le c) \approx 0.9772$.
$P(Z \le \frac{c - 10}{1.5}) = 0.9772$.
D'après la table, le $z$ correspondant est $2.0$.
$\frac{c - 10}{1.5} = 2 \implies c - 10 = 3 \implies c = 13$.
\end{correctionbox}

\begin{correctionbox}[Correction Exercice 8 : CLT (Distribution de $S_n$)]
$E[S_{100}] = n\mu = 100 \times 10 = 1000$.
$\text{Var}(S_{100}) = n\sigma^2 = 100 \times 4 = 400$.
Selon le TCL, $S_{100} \approx \mathcal{N}(1000, 400)$.
\end{correctionbox}

\begin{correctionbox}[Correction Exercice 9 : CLT (Calcul de probabilité pour $S_n$)]
On standardise $S_{100} \approx \mathcal{N}(1000, 400)$, donc $\sigma_{S_n} = \sqrt{400} = 20$.
On cherche $P(S_{100} > 1020)$.
$Z = \frac{S_n - n\mu}{\sigma_{S_n}} = \frac{1020 - 1000}{20} = \frac{20}{20} = 1$.
$P(S_{100} > 1020) = P(Z > 1) = 1 - \Phi(1) \approx 1 - 0.8413 = 0.1587$.
\end{correctionbox}

\begin{correctionbox}[Correction Exercice 10 : CLT (Application $S_n$)]
$n=49, \mu=70, \sigma=14$. $S_{49} \approx \mathcal{N}(n\mu, n\sigma^2)$.
$E[S_{49}] = n\mu = 49 \times 70 = 3430$.
$\sigma_{S_n} = \sigma \sqrt{n} = 14 \times \sqrt{49} = 14 \times 7 = 98$.
On cherche $P(S_{49} > 3500)$.
$Z = \frac{3500 - 3430}{98} = \frac{70}{98} \approx 0.714$.
$P(Z > 0.714)$. (Valeur non fournie, mais le calcul est le Z-score).
\end{correctionbox}

\begin{correctionbox}[Correction Exercice 11 : CLT (Inverse pour $S_n$)]
$n=64, \mu=5, \sigma^2=1$. $S_{64} \approx \mathcal{N}(n\mu, n\sigma^2)$.
$E[S_{64}] = 64 \times 5 = 320$.
$\sigma_{S_n} = \sigma \sqrt{n} = 1 \times \sqrt{64} = 8$.
On cherche $c$ tel que $P(S_{64} > c) \approx 0.05$.
$P(Z > \frac{c - 320}{8}) = 0.05$.
$P(Z \le z) = 0.95$. D'après la table, $z \approx 1.645$.
$\frac{c - 320}{8} = 1.645 \implies c = 320 + 8(1.645) = 320 + 13.16 = 333.16$.
\end{correctionbox}

\begin{correctionbox}[Correction Exercice 12 : Règle d'Approximation]
$n=40, p=0.1$.
$np = 40 \times 0.1 = 4$.
$n(1-p) = 40 \times 0.9 = 36$.
Puisque $np=4$ est $< 10$, la règle n'est pas satisfaite. L'approximation normale n'est pas recommandée.
\end{correctionbox}

\begin{correctionbox}[Correction Exercice 13 : Règle d'Approximation]
$n=500, p=0.04$.
$np = 500 \times 0.04 = 20$.
$n(1-p) = 500 \times 0.96 = 480$.
Les deux conditions ($20 \ge 10$ et $480 \ge 10$) sont satisfaites. L'approximation est valide.
\end{correctionbox}

\begin{correctionbox}[Correction Exercice 14 : Paramètres d'Approximation]
$X \sim \text{Bin}(100, 0.3)$.
$\mu_Y = np = 100 \times 0.3 = 30$.
$\sigma_Y^2 = np(1-p) = 100 \times 0.3 \times 0.7 = 21$.
L'approximation est $Y \sim \mathcal{N}(30, 21)$.
\end{correctionbox}

\begin{correctionbox}[Correction Exercice 15 : Correction de Continuité (Règles)]
1. $P(X = 50) \approx P(49.5 \le Y \le 50.5)$
2. $P(X \ge 50) \approx P(Y \ge 49.5)$
3. $P(X \le 49) \approx P(Y \le 49.5)$
4. $P(X < 49) = P(X \le 48) \approx P(Y \le 48.5)$
\end{correctionbox}

\begin{correctionbox}[Correction Exercice 16 : Correction de Continuité (Règles)]
1. $P(X > 30) = P(X \ge 31) \approx P(Y \ge 30.5)$
2. $P(30 < X < 40) = P(31 \le X \le 39) \approx P(30.5 \le Y \le 39.5)$
3. $P(30 \le X \le 40) \approx P(29.5 \le Y \le 40.5)$
\end{correctionbox}

\begin{correctionbox}[Correction Exercice 17 : Binomiale (Calcul P(X=k))]
$X \sim \text{Bin}(100, 0.5)$. $\mu = 50$, $\sigma^2 = 25$, $\sigma = 5$.
On cherche $P(X=50) \approx P(49.5 \le Y \le 50.5)$.
$Z_1 = \frac{49.5 - 50}{5} = -0.1$. $Z_2 = \frac{50.5 - 50}{5} = 0.1$.
$P(-0.1 \le Z \le 0.1) = \Phi(0.1) - \Phi(-0.1) = \Phi(0.1) - (1 - \Phi(0.1)) = 2\Phi(0.1) - 1$.
$P \approx 2(0.5398) - 1 = 1.0796 - 1 = 0.0796$.
\end{correctionbox}

\begin{correctionbox}[Correction Exercice 18 : Binomiale (Calcul $P(X \ge k)$)]
$X \sim \text{Bin}(100, 0.5)$. $\mu = 50$, $\sigma = 5$.
On cherche $P(X \ge 60) \approx P(Y \ge 59.5)$.
$Z = \frac{59.5 - 50}{5} = \frac{9.5}{5} = 1.9$.
$P(Z \ge 1.9) = 1 - \Phi(1.9)$. (Valeur $\Phi(1.9)$ non fournie, mais $1-\Phi(1.96) \approx 0.025$).
\end{correctionbox}

\begin{correctionbox}[Correction Exercice 19 : Binomiale (Calcul $P(X \le k)$)]
$X \sim \text{Bin}(400, 0.2)$. $np = 80$, $n(1-p)=320$. (Règle OK).
$\mu = 80$. $\sigma^2 = 80 \times 0.8 = 64$. $\sigma = 8$.
On cherche $P(X \le 70) \approx P(Y \le 70.5)$.
$Z = \frac{70.5 - 80}{8} = \frac{-9.5}{8} \approx -1.19$.
$P(Z \le -1.19) = 1 - \Phi(1.19)$. (Valeur non fournie).
\end{correctionbox}

\begin{correctionbox}[Correction Exercice 20 : Binomiale (Calcul $P(X > k)$)]
$X \sim \text{Bin}(400, 0.2)$. $\mu = 80$, $\sigma = 8$.
On cherche $P(X > 92) = P(X \ge 93) \approx P(Y \ge 92.5)$.
$Z = \frac{92.5 - 80}{8} = \frac{12.5}{8} = 1.5625$.
$P(Z \ge 1.5625) \approx P(Z \ge 1.58) = 1 - \Phi(1.58) \approx 1 - 0.9429 = 0.0571$.
\end{correctionbox}

\begin{correctionbox}[Correction Exercice 21 : Binomiale (Calcul $P(k_1 \le X \le k_2)$)]
$X \sim \text{Bin}(100, 0.6)$. $np = 60$, $n(1-p)=40$. (Règle OK).
$\mu = 60$. $\sigma^2 = 60 \times 0.4 = 24$. $\sigma = \sqrt{24} \approx 4.9$.
On cherche $P(50 \le X \le 65) \approx P(49.5 \le Y \le 65.5)$.
$Z_1 = \frac{49.5 - 60}{4.9} = \frac{-10.5}{4.9} \approx -2.14$.
$Z_2 = \frac{65.5 - 60}{4.9} = \frac{5.5}{4.9} \approx 1.12$.
$P(-2.14 \le Z \le 1.12) = \Phi(1.12) - \Phi(-2.14) = \Phi(1.12) - (1 - \Phi(2.14))$. (Valeurs non fournies).
\end{correctionbox}

\begin{correctionbox}[Correction Exercice 22 : TCL vs Chebyshev]
$n=100, \mu=10, \sigma^2=25$. $\bar{X}_{100} \approx \mathcal{N}(10, 25/100=0.25)$. $\sigma_{\bar{X}} = 0.5$.
On cherche $P(|\bar{X}_{100} - 10| \ge 1)$.
1.  **Chebyshev** : $k=1, \text{Var}(\bar{X}_{100}) = 0.25$.
    $P \le \frac{\text{Var}(\bar{X}_{100})}{k^2} = \frac{0.25}{1^2} = 0.25$. (Borne $\le 25\%$).
2.  **CLT** : $P(|\bar{X}_{100} - 10| \ge 1) = P(Z \ge \frac{1}{0.5}) + P(Z \le \frac{-1}{0.5}) = P(Z \ge 2) + P(Z \le -2)$.
    $P = (1 - \Phi(2)) + \Phi(-2) = (1 - \Phi(2)) + (1 - \Phi(2)) = 2(1 - \Phi(2))$.
    $P \approx 2(1 - 0.9772) = 2(0.0228) = 0.0456$. (Probabilité $\approx 4.56\%$).
\end{correctionbox}

\begin{correctionbox}[Correction Exercice 23 : Taille d'Échantillon (CLT)]
$\bar{X}_n \approx \mathcal{N}(\mu, \sigma^2/n) = \mathcal{N}(0, 1/n)$. $\sigma_{\bar{X}} = 1/\sqrt{n}$.
On veut $P(|\bar{X}_n| \le 0.1) \ge 0.95$, soit $P(-0.1 \le \bar{X}_n \le 0.1) \ge 0.95$.
On standardise : $P\left( \frac{-0.1 - 0}{1/\sqrt{n}} \le Z \le \frac{0.1 - 0}{1/\sqrt{n}} \right) \ge 0.95$.
$P(-0.1\sqrt{n} \le Z \le 0.1\sqrt{n}) \ge 0.95$.
On sait que $P(-1.96 \le Z \le 1.96) = 0.95$.
On doit donc avoir $0.1\sqrt{n} \ge 1.96$.
$\sqrt{n} \ge 19.6 \implies n \ge (19.6)^2 = 384.16$.
Il faut $n=385$ échantillons au minimum.
\end{correctionbox}

\begin{correctionbox}[Correction Exercice 24 : LLN vs CLT]
$\mu=10, \sigma^2=100$.
1.  **$n=100$** : $\bar{X}_{100} \approx \mathcal{N}(10, 100/100=1)$. $\sigma_{\bar{X}} = 1$.
    $P(9 \le \bar{X}_{100} \le 11) = P(\frac{9-10}{1} \le Z \le \frac{11-10}{1}) = P(-1 \le Z \le 1)$.
    $P = 2\Phi(1) - 1 \approx 2(0.8413) - 1 = 0.6826$.
2.  **$n=10000$** : $\bar{X}_{10000} \approx \mathcal{N}(10, 100/10000=0.01)$. $\sigma_{\bar{X}} = 0.1$.
    $P(9 \le \bar{X}_{10000} \le 11) = P(\frac{9-10}{0.1} \le Z \le \frac{11-10}{0.1}) = P(-10 \le Z \le 10)$.
    $P \approx \Phi(10) - \Phi(-10) \approx 1 - (1-1) = 1$.
3.  **Illustration** : Le CLT montre \textit{comment} la LLN fonctionne. En augmentant $n$, la variance de $\bar{X}_n$ s'effondre (de 1 à 0.01), forçant la distribution de $\bar{X}_n$ à se concentrer massivement autour de $\mu=10$. La probabilité que $\bar{X}_n$ soit proche de $\mu$ tend vers 1.
\end{correctionbox}

\begin{correctionbox}[Correction Exercice 25 : Binomiale (Sans Correction)]
$X \sim \text{Bin}(400, 0.1)$. On approxime $P(X \le 30.5)$.
$\mu = np = 40$. $\sigma^2 = np(1-p) = 36$. $\sigma = 6$.
$Y \sim \mathcal{N}(40, 36)$.
On cherche $P(Y \le 30.5)$.
$Z = \frac{30.5 - 40}{6} = \frac{-9.5}{6} \approx -1.583$.
$P(Z \le -1.58) = \Phi(-1.58) = 1 - \Phi(1.58) \approx 1 - 0.9429 = 0.0571$.
(Note : C'est le même calcul que l'exercice 19, $P(X \le 30)$, car $P(X \le 30) \approx P(Y \le 30.5)$).
\end{correctionbox}

\subsection{Exercices Python}

Ces exercices utilisent les \textbf{Lois des Grands Nombres (LLN)} pour estimer des paramètres de population à partir de simulations. La LLN garantit que la moyenne d'échantillon ($\bar{X}_n$) converge vers la vraie espérance ($\mu$) lorsque $n$ devient grand.

Nous utiliserons les données de \texttt{yfinance} pour établir des "vraies" valeurs ($\mu, \sigma^2$), puis nous simulerons des échantillons plus petits pour voir comment la moyenne de l'échantillon ($\bar{X}_n$) s'approche de $\mu$.

\begin{codecell}
!pip install yfinance
import yfinance as yf
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import norm

# Definir les tickers et la periode
tickers = ["GOOG"]
start_date = "2010-01-01"
end_date = "2024-12-31"

# Telecharger les prix de cloture ajustes
data = yf.download(tickers, start=start_date, end=end_date)["Adj Close"]

# Calculer les rendements journaliers en pourcentage
returns = data.pct_change().dropna()

# 'returns' est notre DataFrame principal.
# Considerons cette grande serie de donnees comme notre "Population"
# pour les besoins de ces exercices.
population_mean = returns.mean()
population_var = returns.var()
population_std = returns.std()

print(f"--- Population (GOOG 2010-2024) ---")
print(f"Vraie Moyenne (mu) = {population_mean:.6f}")
print(f"Vraie Variance (sigma^2) = {population_var:.6f}")
\end{codecell}

\begin{exercicebox}[Exercice 1 : Vérification de la Loi Faible (WLLN)]
La WLLN dit que $P(|\bar{X}_n - \mu| > \epsilon) \to 0$ lorsque $n \to \infty$. Nous allons vérifier que la variance de $\bar{X}_n$ diminue avec $n$, ce qui est la clé de la preuve de Chebyshev.

La théorie dit : $\text{Var}(\bar{X}_n) = \frac{\sigma^2}{n}$.

\textbf{Votre tâche :}
\begin{enumerate}
    \item Utiliser $\sigma^2$ (la variance de la population) calculée ci-dessus.
    \item Calculer la variance \textbf{théorique} de la moyenne d'échantillon $\text{Var}(\bar{X}_n)$ pour $n=10$, $n=100$, et $n=1000$.
    \item (Conclusion) Comment la variance de notre estimateur $\bar{X}_n$ évolue-t-elle lorsque $n$ augmente ? Qu'est-ce que cela implique sur la précision de notre estimation ?
\end{enumerate}
\end{exercicebox}

\begin{exercicebox}[Exercice 2 : Inégalité de Chebyshev]
Chebyshev donne une borne universelle : $P(|\bar{X}_n - \mu| \ge k) \le \frac{\text{Var}(\bar{X}_n)}{k^2}$.
Utilisons $n=100$ et $\epsilon = 0.01$ (soit un écart de 1\% du rendement journalier).

\textbf{Votre tâche :}
\begin{enumerate}
    \item Utiliser $\text{Var}(\bar{X}_{100})$ calculée à l'exercice 1.
    \item Fixer $k = \epsilon = 0.01$.
    \item Calculer la borne supérieure de probabilité (le côté droit de l'inégalité).
    \item (Conclusion) Interpréter cette borne : "Pour un échantillon de 100 jours, la probabilité que notre moyenne d'échantillon soit erronée de plus de 1\% est, au maximum, de...".
\end{enumerate}
\end{exercicebox}

\begin{exercicebox}[Exercice 3 : Simulation de la Loi Forte (SLLN) - Trajectoire]
La SLLN dit que $P(\lim_{n \to \infty} \bar{X}_n = \mu) = 1$. Nous allons simuler une "trajectoire" de $\bar{X}_n$ pour visualiser cette convergence.

\textbf{Votre tâche :}
\begin{enumerate}
    \item Prendre les 1000 premiers rendements de la série \texttt{returns}.
    \item Calculer la moyenne d'échantillon cumulative $\bar{X}_n$ pour $n=1, 2, 3, \dots, 1000$.
    \item (Indice : utiliser \texttt{.expanding().mean()} de pandas).
    \item \textbf{(Plot)} Tracer $\bar{X}_n$ en fonction de $n$ (de 1 à 1000).
    \item \textbf{(Plot)} Tracer une ligne horizontale constante à la "vraie" moyenne $\mu$ (la \texttt{population\_mean}).
    \item (Conclusion) La trajectoire de $\bar{X}_n$ converge-t-elle vers $\mu$ ?
\end{enumerate}
\end{exercicebox}

\begin{exercicebox}[Exercice 4 : Méthode de Monte-Carlo (Estimation de Probabilité)]
Nous voulons estimer $p = P(X > 0.02)$, la probabilité d'un "gros jour positif" (rendement > 2\%).
La vraie valeur $p$ est la proportion empirique sur toute la "population".
L'estimation $\bar{Z}_n$ est la proportion sur un échantillon de $n$ jours.

\textbf{Votre tâche :}
\begin{enumerate}
    \item Calculer la "vraie" probabilité $p$ (notre $\mu$) en comptant la proportion de \texttt{returns > 0.02} sur tout le dataset.
    \item Simuler 500 expériences. Dans \textbf{chaque} expérience :
        \begin{itemize}
            \item Tirer un échantillon de $n=50$ jours (avec remise) de \texttt{returns}.
            \item Estimer $\bar{Z}_{50}$ (la proportion de jours $> 0.02$ dans cet échantillon).
        \end{itemize}
    \item \textbf{(Plot)} Tracer l'histogramme de vos 500 estimations $\bar{Z}_{50}$.
    \item \textbf{(Plot)} Ajouter une ligne verticale à la "vraie" moyenne $p$.
    \item (Conclusion) Les estimations sont-elles centrées autour de la vraie valeur, comme prédit par la LLN ?
\end{enumerate}
\end{exercicebox}

\begin{exercicebox}[Exercice 5 : Estimation de $\pi$ (Monte-Carlo Pur)]
Appliquons l'exemple du cours pour estimer $\pi$ en utilisant la LLN.
Nous cherchons $\mu = \pi/4$. Nous estimons $\mu$ par $\bar{Z}_n = \frac{\text{Points dans le cercle}}{n}$.

\textbf{Votre tâche (avec NumPy) :}
\begin{enumerate}
    \item Définir $n = 1,000,000$.
    \item Générer $n$ coordonnées $X \sim U(0, 1)$ et $n$ coordonnées $Y \sim U(0, 1)$.
    \item Calculer $Z_i = 1$ si $X_i^2 + Y_i^2 \le 1$, et $0$ sinon. (Indice : \texttt{np.where} ou une comparaison booléenne).
    \item Calculer $\bar{Z}_n$ (la moyenne de $Z$).
    \item Calculer votre estimation de $\pi \approx 4 \cdot \bar{Z}_n$.
    \item (Conclusion) Votre estimation est-elle proche de \texttt{math.pi} ?
\end{enumerate}
\end{exercicebox}