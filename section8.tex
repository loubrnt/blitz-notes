\newpage
\section{La Loi Normale (ou Gaussienne)}

\subsection{Introduction et Fonction de Densité (PDF)}

\begin{definitionbox}[Loi Normale]
Une variable aléatoire continue $X$ suit une \textbf{loi normale} (ou loi de Gauss) de paramètres $\mu$ (l'espérance) et $\sigma^2$ (la variance), notée $X \sim \mathcal{N}(\mu, \sigma^2)$, si sa fonction de densité de probabilité (PDF) est donnée par :
$$ f(x; \mu, \sigma) = \frac{1}{\sigma \sqrt{2\pi}} e^{ -\frac{1}{2} \left( \frac{x-\mu}{\sigma} \right)^2 } $$
pour tout $x \in (-\infty, \infty)$, où $\sigma > 0$.
\end{definitionbox}

\begin{intuitionbox}[La Courbe en Cloche]
La loi normale est sans doute la distribution la plus importante en probabilités et statistiques. Pourquoi ? Parce qu'elle modélise remarquablement bien de nombreux phénomènes naturels et processus aléatoires où les valeurs tendent à se regrouper autour d'une moyenne, avec des écarts symétriques devenant de plus en plus rares à mesure qu'on s'éloigne de cette moyenne. Pensez à la taille des individus dans une population, aux erreurs de mesure répétées, ou même aux notes d'un grand groupe d'étudiants à un examen bien conçu. 

Sa densité a une forme caractéristique de \textbf{cloche symétrique} :
\begin{itemize}
    \item \textbf{Le Centre ($\mu$)} : Le paramètre $\mu$ représente l'\textbf{espérance} (la moyenne) de la distribution. C'est le centre de symétrie de la courbe, là où la cloche atteint son \textbf{sommet}. C'est la valeur la plus probable (le mode) et aussi la valeur qui coupe la distribution en deux moitiés égales (la médiane). Changer $\mu$ \textit{translate} la cloche horizontalement sans changer sa forme.
    \item \textbf{La Dispersion ($\sigma$)} : Le paramètre $\sigma$ est l'\textbf{écart-type} ($\sigma^2$ est la variance). Il mesure la \textbf{dispersion} des valeurs autour de la moyenne $\mu$. Géométriquement, $\sigma$ contrôle la \textbf{largeur} de la cloche.
        \begin{itemize}
            \item Un \textit{petit} $\sigma$ signifie que les données sont très concentrées autour de la moyenne, donnant une cloche \textbf{étroite et pointue}.
            \item Un \textit{grand} $\sigma$ signifie que les données sont plus étalées, donnant une cloche \textbf{large et aplatie}.
        \end{itemize}
    Les points d'inflexion de la courbe (là où la courbure change de sens) se situent exactement à $\mu \pm \sigma$.
\end{itemize}

\tcblower
\centering
\begin{tikzpicture}
    \begin{axis}[
        title={La Courbe en Cloche (PDF de la Loi Normale)},
        xlabel={$x$},
        ylabel={$f(x)$},
        axis lines=middle,
        no markers,
        samples=100,
        domain=-4:4,
        height=8cm,
        width=\linewidth-1cm,
        tick label style={font=\tiny},
        legend style={at={(0.5,-0.15)}, anchor=north, font=\small},
        legend columns=2
    ]
    % N(0, 1)
    \addplot [blue, ultra thick] {1/(sqrt(2*pi))*exp(-x^2/2)};
    \addlegendentry{$\mu=0, \sigma=1$};
    % N(0, 0.25) => sigma=0.5
    \addplot [red, ultra thick] {1/(0.5*sqrt(2*pi))*exp(-x^2/(2*0.5^2))};
    \addlegendentry{$\mu=0, \sigma=0.5$ (étroite)};
    % N(1, 2.25) => sigma=1.5
    \addplot [green!70!black, ultra thick] {1/(1.5*sqrt(2*pi))*exp(-(x-1)^2/(2*1.5^2))};
    \addlegendentry{$\mu=1, \sigma=1.5$ (large, décalée)};

    \draw [dashed] (axis cs:0,0) -- (axis cs:0, {1/(sqrt(2*pi))}) node[above, font=\tiny] {pic à $\mu=0$}; % Ligne pour mu=0
    \draw [dashed] (axis cs:1,0) -- (axis cs:1, {1/(1.5*sqrt(2*pi))}) node[above right, font=\tiny] {pic à $\mu=1$}; % Ligne pour mu=1
    \end{axis}
\end{tikzpicture}
\par\small\textit{Influence de $\mu$ (position) et $\sigma$ (largeur) sur la forme de la cloche.}
\end{intuitionbox}

\begin{proofbox}[Dérivation de la Densité Normale à partir des Principes Fondamentaux]

\textbf{Contexte Visuel :} Imaginons un nuage de points dispersés autour d'une cible à l'origine $(0,0)$, comme des impacts de fléchettes. Le graphique ci-dessous illustre cette dispersion. On s'intéresse à la probabilité de tomber dans une petite zone, comme $dA$, autour d'un point $(x, y)$.

\begin{center}
\begin{tikzpicture}
\begin{axis}[
    axis lines=middle, % Axes qui passent par l'origine (0,0)
    xlabel=$x$,       % Étiquette axe X
    ylabel=$y$,       % Étiquette axe Y
    axis line style={magenta}, % Couleur des axes
    xlabel style={anchor=west, magenta}, % Style de l'étiquette X
    ylabel style={anchor=south, magenta}, % Style de l'étiquette Y
    xmin=-3.5, xmax=3.5, % Limites du graphique
    ymin=-3.5, ymax=3.5,
    tick label style={font=\tiny} % Police plus petite pour les graduations
]

% Ajout des points du nuage. Ce sont des coordonnées approximatives.
\addplot [only marks, mark=*, cyan, mark size=1.5pt]
coordinates {
    (0.2, 0.1) (-0.5, 0.2) (0.1, -0.3) (0.5, -0.8) (-0.3, -1.2) (0,0.1)
    (1.5, 1.5) (0.8, 0.8) (2.0, -0.5) (2.8, -1.4) (2.5, -0.2)
    (-1.8, -1.3) (-2.5, 0.5) (-1.5, 0.3) (-2.2, -0.8) (-0.8, 0.5)
    (0.5, 1.2) (0.7, 2.8) (0.2, 3.2) (-0.5, 1.5) (-1.0, -2.0)
    (1.8, -1.0) (1.0, -1.5) (0.3, -2.5) (-1.8, -2.8) (1.2, 0.5)
    (-1.2, -1.5) (-0.8, 1.1)
};

% --- Annotations ---

% Points et boîte pour 'dA'
\addplot [only marks, mark=*, red, mark size=1.5pt] coordinates {(1.3, 2.0)};
\draw [red, thick] (axis cs:1.1, 1.8) rectangle (axis cs:1.5, 2.2);
\node [red, above] at (axis cs:1.3, 2.2) {$dA$};

% Points et boîte pour 'dB'
\addplot [only marks, mark=*, cyan, mark size=1.5pt] 
coordinates {(-1.2, 2.0) (-1.3, 2.3) (-1.0, 2.2) (-1.1, 1.9)};
\draw [blue, thick] (axis cs:-1.8, 1.2) rectangle (axis cs:-0.8, 2.8);
\node [blue, above] at (axis cs:-1.3, 2.8) {$dB$};

\end{axis}
\end{tikzpicture}
\end{center}

\textbf{Objectif :} Expliquer comment arriver à la formule mathématique de la courbe en cloche (densité de probabilité normale) en partant de principes fondamentaux sur les erreurs aléatoires.

\textbf{1. Le Point de Départ : Densité et Aire $dA$}
\newline
Dans une distribution continue, la probabilité de tomber \textit{exactement} sur un point $(x, y)$ est nulle. On ne peut donc pas parler de "probabilité d'un point". On parle de la probabilité de tomber \textit{dans une petite zone}, comme un rectangle $dA = dx \cdot dy$ autour du point $(x, y)$.

Cette probabilité, notée $P(\text{dans } dA)$, est \textit{proportionnelle} à l'aire de la zone $dA$. La \textit{constante de proportionnalité} est la \textbf{fonction de densité de probabilité} $p(x, y)$ évaluée en ce point. En d'autres termes, la densité $p(x, y)$ \textit{représente} localement la concentration de probabilité. Ainsi, la probabilité de tomber dans la zone $dA$ est approximativement :

$$ P(\text{dans } dA) \approx p(x, y) \cdot dA $$

Donc, $p(x, y)$ est la \textit{densité de probabilité} en $(x, y)$, et non la probabilité elle-même multipliée par l'aire. La probabilité totale sur une zone finie est obtenue en intégrant cette densité sur cette zone.

\textbf{2. Les Hypothèses Fondamentales}
\newline
On pose deux hypothèses sur la nature de ces erreurs (représentées par la densité $p(x, y)$) :
\begin{enumerate}
    \item \textbf{Indépendance des axes :} L'erreur horizontale ($x$) est indépendante de l'erreur verticale ($y$). Cela implique que la densité jointe $p(x, y)$ peut s'écrire comme le produit de la densité marginale sur $x$, notée $f(x)$, et de la densité marginale sur $y$, notée $f(y)$. Donc, $p(x, y) = f(x) \cdot f(y)$.
    \item \textbf{Symétrie de rotation (Isotropie) :} La densité ne dépend que de la distance $r = \sqrt{x^2 + y^2}$ au centre, pas de l'angle. Il existe donc une fonction $\phi(r)$ telle que la densité en $(x,y)$ est $p(x, y) = \phi(\sqrt{x^2 + y^2})$.
\end{enumerate}

\textbf{3. L'Équation Fonctionnelle}
\newline
En égalant les deux expressions pour la même densité $p(x, y)$ (à une constante près, car la densité peut être définie à un facteur près avant normalisation), on obtient :
$$ f(x) \cdot f(y) = \phi(\sqrt{x^2 + y^2}) $$
Pour $y=0$, on a $f(x) \cdot f(0) = \phi(x)$. Posons $f(0) = \lambda$ (la densité maximale au centre). Alors $\phi(x) = \lambda f(x)$.
L'équation devient :
$$ f(x) \cdot f(y) = \lambda f(\sqrt{x^2 + y^2}) $$

\textbf{4. Résolution de l'Équation Fonctionnelle}
\begin{enumerate}
    \item \textbf{Normalisation :} Posons $g(x) = f(x)/\lambda$, avec $g(0)=1$. L'équation se simplifie en :
    $$ g(x) g(y) = g(\sqrt{x^2 + y^2}) $$
    \item \textbf{Changement de variable :} Posons $g(x) = h(x^2)$. L'équation devient $h(x^2)h(y^2) = h(x^2+y^2)$. Avec $a=x^2$ et $b=y^2$, on a :
    $$ h(a) h(b) = h(a+b) $$
    \item \textbf{Solution exponentielle :} La solution continue de cette équation de Cauchy est $h(a) = e^{Aa}$ pour une constante $A$.
    \item \textbf{Retour aux fonctions et contrainte physique :}
    $g(x) = h(x^2) = e^{Ax^2}$.
    $f(x) = \lambda g(x) = \lambda e^{Ax^2}$.
    Comme la densité doit diminuer loin du centre, la constante $A$ doit être négative. Posons $A = -k$ avec $k>0$.
    $$ f(x) = \lambda e^{-k x^2} $$
\end{enumerate}

\textbf{5. Normalisation et Identification des Paramètres}
\begin{enumerate}
    \item \textbf{Condition $\int f(x) dx = 1$} :
    $\int_{-\infty}^{\infty} \lambda e^{-k x^2} \, \mathrm{d}x = \lambda \sqrt{\frac{\pi}{k}} = 1 \implies \lambda = \sqrt{\frac{k}{\pi}}$.
    \item \textbf{Lien avec la Variance ($\sigma^2$)} : Pour une distribution centrée, $\sigma^2 = E[X^2] = \int x^2 f(x) dx$.
    $$ \sigma^2 = \int_{-\infty}^{\infty} x^2 \left( \sqrt{\frac{k}{\pi}} e^{-k x^2} \right) \, \mathrm{d}x = \sqrt{\frac{k}{\pi}} \left( \frac{1}{2k} \sqrt{\frac{\pi}{k}} \right) = \frac{1}{2k} $$
    Donc, $k = \frac{1}{2\sigma^2}$.
    \item \textbf{Substitution Finale :} Remplaçons $k$ dans $\lambda$ et $f(x)$.
    $$ \lambda = \sqrt{\frac{1/(2\sigma^2)}{\pi}} = \frac{1}{\sigma\sqrt{2\pi}} $$
    $$ f(x) = \frac{1}{\sigma\sqrt{2\pi}} e^{-\frac{1}{2\sigma^2} x^2} = \frac{1}{\sigma\sqrt{2\pi}} e^{ -\frac{x^2}{2\sigma^2} } $$
    \item \textbf{Généralisation (Moyenne $\mu$)} : Pour centrer la distribution sur $\mu$, on remplace $x$ par $(x-\mu)$ dans l'exposant :
    $$ f(x; \mu, \sigma) = \frac{1}{\sigma \sqrt{2\pi}} e^{ -\frac{(x-\mu)^2}{2\sigma^2} } $$
\end{enumerate}
C'est la fonction de densité de la loi normale $\mathcal{N}(\mu, \sigma^2)$, dérivée des hypothèses fondamentales sur les erreurs aléatoires.
\end{proofbox}

\subsection{La Loi Normale Centrée Réduite $\mathcal{N}(0, 1)$}

\begin{definitionbox}[Loi Normale Standard (ou Centrée Réduite)]
Un cas particulier extraordinairement utile est la loi normale avec une moyenne $\mu=0$ et une variance $\sigma^2=1$ (donc $\sigma=1$). On l'appelle la \textbf{loi normale standard} ou \textbf{centrée réduite}, et on la note souvent $Z$. Sa PDF est traditionnellement notée $\phi(z)$ :
$$ \phi(z) = \frac{1}{\sqrt{2\pi}} e^{-z^2/2} $$
Sa fonction de répartition (CDF), qui donne $P(Z \le z)$, est notée $\Phi(z)$ :
$$ \Phi(z) = P(Z \le z) = \int_{-\infty}^z \frac{1}{\sqrt{2\pi}} e^{-t^2/2} \, \mathrm{d}t $$
\end{definitionbox}

\begin{intuitionbox}[La Référence Universelle et le Changement d'Unités]
Pourquoi cette loi $\mathcal{N}(0, 1)$ est-elle si centrale ? Imaginez que vous ayez des mesures en degrés Celsius ($\mathcal{N}(\mu_C, \sigma_C^2)$) et d'autres en degrés Fahrenheit ($\mathcal{N}(\mu_F, \sigma_F^2)$). Comment les comparer ? La loi normale standard fournit un \textbf{système d'unités universel}.
\newline
Toute variable normale $X \sim \mathcal{N}(\mu, \sigma^2)$ peut être transformée ("standardisée") en une variable $Z \sim \mathcal{N}(0, 1)$ par un simple changement d'échelle et de position : $Z = (X-\mu)/\sigma$. 
\newline
Cela signifie qu'au lieu de devoir calculer des aires (probabilités) pour une infinité de courbes en cloche différentes (une pour chaque paire $\mu, \sigma$), on peut tout ramener à \textbf{une seule courbe de référence}, $\mathcal{N}(0, 1)$. Les aires sous cette courbe standard ($\Phi(z)$) ont été calculées une fois pour toutes et sont disponibles dans des tables ou des logiciels. On n'a plus qu'à convertir notre problème dans cette "langue" standard, trouver la probabilité, et interpréter le résultat.
\end{intuitionbox}

\begin{remarquebox}[Notation $\phi$ et $\Phi$]
Les symboles $\phi$ (phi minuscule) pour la PDF et $\Phi$ (phi majuscule) pour la CDF de la loi normale standard sont quasi universels. Il est important de ne pas les confondre. $\phi(z)$ est la \textit{hauteur} de la courbe en $z$, tandis que $\Phi(z)$ est l'\textit{aire} sous la courbe à gauche de $z$.
\end{remarquebox}

\begin{remarquebox}[Absence de Primitive Simple]
L'intégrale $\int e^{-t^2/2} \, \mathrm{d}t$, nécessaire pour calculer $\Phi(z)$, n'a \textbf{pas d'expression analytique} en termes de fonctions élémentaires (polynômes, exponentielles, log, sin, cos...). C'est une fonction spéciale, connue sous le nom de \textbf{fonction d'erreur} (liée à $\Phi$ par une transformation simple). C'est la raison pour laquelle on dépend de tables ou de calculs numériques pour obtenir les valeurs de $\Phi(z)$. Heureusement, ces outils sont omniprésents aujourd'hui.
\end{remarquebox}

\subsection{Standardisation : Le Score Z}

\begin{theorembox}[Standardisation d'une Variable Normale]
Si $X \sim \mathcal{N}(\mu, \sigma^2)$, alors la variable $Z$ définie par :
$$ Z = \frac{X - \mu}{\sigma} $$
suit la loi normale standard, $Z \sim \mathcal{N}(0, 1)$.
\end{theorembox}

\begin{intuitionbox}[Mesurer en "Unités d'Écart-Type"]
Transformer $X$ en $Z$ s'appelle \textbf{standardiser} la variable. Le résultat, $z = \frac{x-\mu}{\sigma}$, est appelé le \textbf{Score Z} (ou cote Z). Ce score Z est une mesure \textit{sans unité} qui indique \textbf{à combien d'écarts-types} une valeur observée $x$ se situe par rapport à la moyenne $\mu$ de sa distribution.
\begin{itemize}
    \item $z = 0$ : $x$ est exactement à la moyenne ($\mathbf{x = \mu}$).
    \item $z = +1$ : $x$ est un écart-type \textit{au-dessus} de la moyenne ($\mathbf{x = \mu + \sigma}$).
    \item $z = -2$ : $x$ est deux écarts-types \textit{en dessous} de la moyenne ($\mathbf{x = \mu - 2\sigma}$).
\end{itemize}
Cette transformation est extrêmement utile pour :
\begin{enumerate}
    \item \textbf{Comparer des valeurs} issues de distributions normales différentes. Un score Z de +1.5 a toujours la même signification relative, que l'on parle de QI, de taille, ou de température.
    \item \textbf{Calculer des probabilités} en utilisant la table unique de la loi $\mathcal{N}(0, 1)$.
\end{enumerate}
\end{intuitionbox}

\begin{examplebox}[Comparaison de Performances]
Un étudiant A obtient 80 points à un examen où la moyenne est $\mu_A=70$ et l'écart-type $\sigma_A=5$. Un étudiant B obtient 85 points à un autre examen où $\mu_B=75$ et $\sigma_B=10$. Qui a le mieux réussi relativement à son groupe ?
\newline
Calculons les Z-scores :
$$ Z_A = \frac{80 - 70}{5} = \frac{10}{5} = +2.0 $$
$$ Z_B = \frac{85 - 75}{10} = \frac{10}{10} = +1.0 $$
L'étudiant A a un score Z plus élevé (+2.0 contre +1.0), ce qui signifie qu'il se situe plus d'écarts-types au-dessus de la moyenne de son groupe que l'étudiant B. L'étudiant A a donc relativement mieux réussi.
\end{examplebox}

\subsection{Propriétés Importantes de la Loi Normale}

\begin{theorembox}[Stabilité par Transformation Linéaire]
Si $X \sim \mathcal{N}(\mu, \sigma^2)$ et $Y = aX + b$ (avec $a \neq 0$), alors $Y$ suit aussi une loi normale :
$$ Y \sim \mathcal{N}(a\mu + b, \, (a\sigma)^2) $$
L'espérance est transformée linéairement ($E[aX+b] = aE[X]+b$), et la variance est multipliée par $a^2$ ($\text{Var}(aX+b) = a^2\text{Var}(X)$).
\end{theorembox}

\begin{examplebox}[Changement d'Unités]
Si la température en Celsius $T_C$ suit $\mathcal{N}(20, 5^2)$, quelle est la loi de la température en Fahrenheit $T_F = \frac{9}{5}T_C + 32$ ?
\newline
$a = 9/5$, $b=32$.
\newline
Nouvelle moyenne : $E[T_F] = \frac{9}{5}(20) + 32 = 36 + 32 = 68$.
\newline
Nouvel écart-type : $\sigma_{T_F} = |a|\sigma_{T_C} = \frac{9}{5}(5) = 9$. Nouvelle variance : $\sigma_{T_F}^2 = 9^2 = 81$.
\newline
Donc, $T_F \sim \mathcal{N}(68, 9^2)$.
\end{examplebox}

\begin{theorembox}[Stabilité par Addition (Indépendance)]
Si $X \sim \mathcal{N}(\mu_X, \sigma_X^2)$ et $Y \sim \mathcal{N}(\mu_Y, \sigma_Y^2)$ sont des variables aléatoires \textbf{indépendantes}, alors leur somme $S = X + Y$ suit aussi une loi normale :
$$ S \sim \mathcal{N}(\mu_X + \mu_Y, \, \sigma_X^2 + \sigma_Y^2) $$
Les moyennes s'ajoutent, et (grâce à l'indépendance) les variances s'ajoutent.
\end{theorembox}

\begin{remarquebox}[Attention à l'Indépendance]
La propriété d'addition des variances ($\sigma_S^2 = \sigma_X^2 + \sigma_Y^2$) est cruciale et ne tient \textbf{que si $X$ et $Y$ sont indépendantes}. Si elles ne le sont pas, la variance de la somme inclut un terme de covariance : $\text{Var}(X+Y) = \text{Var}(X) + \text{Var}(Y) + 2\text{Cov}(X, Y)$. Cependant, la somme de variables normales (même dépendantes) reste normale (si elles sont conjointement normales).
\end{remarquebox}

\begin{examplebox}[Poids Total]
Le poids d'une pomme suit $\mathcal{N}(150g, 10^2)$. Le poids d'une orange suit $\mathcal{N}(200g, 15^2)$. On suppose les poids indépendants. Quel est la loi du poids total d'une pomme et d'une orange ?
\newline
Soit $P$ le poids de la pomme, $O$ celui de l'orange. $T = P+O$.
\newline
$E[T] = E[P] + E[O] = 150 + 200 = 350g$.
\newline
$\text{Var}(T) = \text{Var}(P) + \text{Var}(O) = 10^2 + 15^2 = 100 + 225 = 325$.
\newline
Donc, $T \sim \mathcal{N}(350, 325)$. L'écart-type du poids total est $\sqrt{325} \approx 18.03g$.
\end{examplebox}

\subsection{La Règle Empirique (68-95-99.7)}

\begin{theorembox}[Règle Empirique]
Pour toute variable $X \sim \mathcal{N}(\mu, \sigma^2)$ :
\begin{itemize}
    \item $P(\mu - \sigma \le X \le \mu + \sigma) \approx 0.6827$ (Environ \textbf{68\%} des valeurs dans $\mu \pm \sigma$).
    \item $P(\mu - 2\sigma \le X \le \mu + 2\sigma) \approx 0.9545$ (Environ \textbf{95\%} des valeurs dans $\mu \pm 2\sigma$).
    \item $P(\mu - 3\sigma \le X \le \mu + 3\sigma) \approx 0.9973$ (Environ \textbf{99.7\%} des valeurs dans $\mu \pm 3\sigma$).
\end{itemize}
\end{theorembox}

\begin{intuitionbox}[Repères Essentiels sur la Cloche]
Cette règle, dérivée directement des aires sous la courbe $\mathcal{N}(0, 1)$ entre $z=\pm 1$, $z=\pm 2$ et $z=\pm 3$, fournit des repères extrêmement utiles pour interpréter l'écart-type $\sigma$. Elle nous dit où se trouve la grande majorité des données.
\newline
Une observation qui tombe en dehors de l'intervalle $\mu \pm 3\sigma$ est très inhabituelle (elle n'a que 0.3pct de chances de se produire). C'est souvent considéré comme une \textit{valeur aberrante} (outlier) potentielle.
\end{intuitionbox}

\subsection{Calcul de Probabilités Normales}

\begin{examplebox}[Utilisation du Z-score]
Supposons que le QI d'une population suit $\mathcal{N}(100, 15^2)$. Quelle est la probabilité $P(X > 130)$ ?

1.  \textbf{Standardiser :} $z = \frac{130 - 100}{15} = 2$. On cherche $P(Z > 2)$.
2.  \textbf{Utiliser la CDF Standard :} $P(Z > 2) = 1 - P(Z \le 2) = 1 - \Phi(2)$.
3.  \textbf{Chercher dans la table / Calculer :} $\Phi(2) \approx 0.9772$.
4.  \textbf{Résultat :} $P(X > 130) = 1 - 0.9772 = 0.0228$.
\end{examplebox}

\begin{examplebox}[Probabilité entre deux valeurs]
Quelle est la probabilité $P(85 \le X \le 115)$ ?

1.  \textbf{Standardiser :} $z_1 = \frac{85 - 100}{15} = -1$, $z_2 = \frac{115 - 100}{15} = 1$. On cherche $P(-1 \le Z \le 1)$.
2.  \textbf{Utiliser la CDF Standard :} $P(-1 \le Z \le 1) = \Phi(1) - \Phi(-1)$.
3.  \textbf{Utiliser la symétrie :} $\Phi(-z) = 1 - \Phi(z)$. Donc $\Phi(-1) = 1 - \Phi(1)$.
    $P(-1 \le Z \le 1) = \Phi(1) - (1 - \Phi(1)) = 2\Phi(1) - 1$.
4.  \textbf{Chercher dans la table / Calculer :} $\Phi(1) \approx 0.8413$.
5.  \textbf{Résultat :} $P(85 \le X \le 115) \approx 2(0.8413) - 1 = 1.6826 - 1 = 0.6826$.
\end{examplebox}

\begin{examplebox}[Trouver une valeur pour une probabilité donnée (Problème Inverse)]
Quel est le QI minimum requis pour être dans le top 10\% de la population ? ($\mu=100, \sigma=15$).

1.  \textbf{Trouver le Z-score correspondant :} On cherche $x$ tel que $P(X > x) = 0.10$. Cela équivaut à $P(Z > z) = 0.10$, où $z = (x-100)/15$.
    Si $P(Z > z) = 0.10$, alors $P(Z \le z) = \Phi(z) = 1 - 0.10 = 0.90$.
2.  \textbf{Chercher dans la table inverse / Calculer :} On cherche la valeur $z$ pour laquelle l'aire à gauche est 0.90. On trouve $z \approx 1.28$.
3.  \textbf{Convertir en X :} On utilise la relation $z = (x-\mu)/\sigma$ pour trouver $x$:
    $1.28 = \frac{x - 100}{15}$
    $x = 100 + 1.28 \times 15 = 100 + 19.2 = 119.2$.
    Il faut un QI d'environ 119.2 pour être dans le top 10\%.
\end{examplebox}
